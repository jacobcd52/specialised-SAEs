{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fe8994dc940>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/root/specialised-SAEs\")\n",
    "from datasets import load_dataset\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "import gc\n",
    "import torch\n",
    "from sae_lens.sae import SAE\n",
    "from load_sae_from_hf import load_sae_from_hf\n",
    "from analysis_fns import get_owt_and_spec_tokens, get_l0_freqs_loss_fvu, sweep, get_freq_plots, get_cossim_plots\n",
    "from sae_lens.config import DTYPE_MAP\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from huggingface_hub import login, HfApi, create_repo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "login(token=\"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\")\n",
    "api = HfApi()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 20_000\n",
    "DTYPE = \"bfloat16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8221d93ac424796bb384ae42d46e12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sae_weights.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64a346935a74623956599c64cc319cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cfg.json:   0%|          | 0.00/786 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df49d76e5014ef290cd457f48699fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b-it into HookedTransformer\n",
      "Sanity check:\n",
      "GSAE error norm = 33.2\n",
      "Input act norm = 692.0\n"
     ]
    }
   ],
   "source": [
    "# Load SAEs, model and dataset\n",
    "gsae = load_sae_from_hf(\"jacobcd52/gemma2-gsae\", \n",
    "                        \"sae_weights.safetensors\", \n",
    "                        \"cfg.json\",\n",
    "                        device=\"cuda\", dtype=DTYPE)\n",
    "model = HookedTransformer.from_pretrained_no_processing(\"gemma-2b-it\", device=\"cuda\", dtype=DTYPE)\n",
    "\n",
    "# Sanity check: the GSAE error should be smaller than the original activation\n",
    "loss, cache = model.run_with_cache(\"My name is Jacob, and I come from London, England.\", return_type=\"loss\", names_filter=[gsae.cfg.hook_name])\n",
    "act = cache[gsae.cfg.hook_name]\n",
    "print(\"\\n\\nSanity check:\")\n",
    "print(f\"GSAE error norm = {(gsae(act) - act)[:,1:].norm().item():.1f}\")\n",
    "print(f\"Input act norm = {act.norm().item():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c851d5d5f9f4c8d8ed58fcabf5da075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)2000_gsae_id=layer_12_stepan.safetensors:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29995e32af24b76adb50282c6c3e2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)8192000_gsae_id=layer_12_stepan_cfg.json:   0%|          | 0.00/2.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1591187733f4f2191c8417a74a5e951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)2000_gsae_id=layer_12_stepan.safetensors:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5412532c4eee49f382965cb8c6c07ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)8192000_gsae_id=layer_12_stepan_cfg.json:   0%|          | 0.00/2.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9c478610cc404ea328f4ebc813775d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)5_expansion=2_tokens=8192000.safetensors:   0%|          | 0.00/33.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85116ff09e27478e9aba2f164257024e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l1=5_expansion=2_tokens=8192000_cfg.json:   0%|          | 0.00/2.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b48cbb244584d1bb1c8d4b57aa7f4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)2_expansion=2_tokens=8192000.safetensors:   0%|          | 0.00/33.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5671c3f55874a289e0a6386c44cf7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l1=2_expansion=2_tokens=8192000_cfg.json:   0%|          | 0.00/2.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba5a898b961466590256fdb4443a953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)_expansion=16_tokens=8192000.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33346a28be224d4f80195346eecf1d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)1=4_expansion=16_tokens=8192000_cfg.json:   0%|          | 0.00/2.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45621a8d3f5c4d42803860c44b06dcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)_expansion=16_tokens=8192000.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f57bf6c50f471b91110037aa014bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)1=2_expansion=16_tokens=8192000_cfg.json:   0%|          | 0.00/2.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "context length = 128\n",
      "hook point = blocks.12.hook_resid_pre\n",
      "owt_tokens has shape torch.Size([19962, 128])\n",
      "total number of tokens: 2 million\n",
      "\n",
      "spec_tokens has shape torch.Size([19811, 128])\n",
      "total number of tokens: 2 million\n"
     ]
    }
   ],
   "source": [
    "########### SET THESE ############\n",
    "ssae_l1_list = [20,10] #[20, 10, 6]\n",
    "direct_sae_l1_list = [5, 2] # [5, 2, 1]\n",
    "gsae_ft_l1_list = [4, 2] #[4, 2, 1, 0.5]\n",
    "\n",
    "subject = \"hs_bio_cleaned\"\n",
    "spec_path = f\"jacobcd52/{subject}\"\n",
    "##################################\n",
    "\n",
    "\n",
    "ssae_list = [load_sae_from_hf(f\"jacobcd52/gemma-2b-it-ssae-{subject}\",\n",
    "                           f\"gemma-2b-it_layer12_{subject}_l1={l1}_expansion=2_tokens=8192000_gsae_id=layer_12_stepan.safetensors\",\n",
    "                           f\"gemma-2b-it_layer12_{subject}_l1={l1}_expansion=2_tokens=8192000_gsae_id=layer_12_stepan_cfg.json\",\n",
    "                           device=\"cuda\", dtype=DTYPE)\n",
    "            for l1 in ssae_l1_list]\n",
    "\n",
    "direct_sae_list = [load_sae_from_hf(f\"jacobcd52/gemma-2b-it-directsae-{subject}\",\n",
    "                                    f\"gemma-2b-it_layer12_{subject}_l1={l1}_expansion=2_tokens=8192000.safetensors\",\n",
    "                                    f\"gemma-2b-it_layer12_{subject}_l1={l1}_expansion=2_tokens=8192000_cfg.json\",\n",
    "                                    device=\"cuda\", dtype=DTYPE)\n",
    "            for l1 in direct_sae_l1_list]\n",
    "\n",
    "gsae_ft_list = [load_sae_from_hf(f\"jacobcd52/gemma-2b-it-gsae-ft-{subject}\",\n",
    "                                 f\"gsaefinetune_gemma-2b-it_layer12_{subject}_l1={l1}_expansion=16_tokens=8192000.safetensors\",\n",
    "                                 f\"gsaefinetune_gemma-2b-it_layer12_{subject}_l1={l1}_expansion=16_tokens=8192000_cfg.json\",\n",
    "                                device=\"cuda\", dtype=DTYPE)\n",
    "            for l1 in gsae_ft_l1_list]\n",
    "for sae in gsae_ft_list:\n",
    "    sae.cfg.apply_b_dec_to_input = False\n",
    "\n",
    "all_ctx_lengths = [gsae.cfg.context_size] + [sae.cfg.context_size for sae in ssae_list + direct_sae_list + gsae_ft_list]\n",
    "ctx_length = min(all_ctx_lengths)\n",
    "print(\"context length =\", ctx_length)\n",
    "\n",
    "all_hook_pts = set([gsae.cfg.hook_name] + [sae.cfg.hook_name for sae in ssae_list + gsae_ft_list])\n",
    "assert len(all_hook_pts) == 1, \"All models must have the same hook point\"\n",
    "hook_pt = all_hook_pts.pop()\n",
    "print(\"hook point =\", hook_pt)\n",
    "\n",
    "owt_tokens, spec_tokens = get_owt_and_spec_tokens(model, f\"jacobcd52/{subject}\", ctx_length=ctx_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subject(model, subject, num_tokens=100_000):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Get floor and ceiling losses (i.e. clean and with GSAE)\n",
    "    print(f\"\\n\\ngetting floor and ceiling losses for {subject}\\n\")\n",
    "    _, _, clean_owt_losses, _  = get_l0_freqs_loss_fvu(model, \"clean\", owt_tokens)\n",
    "    _, _, clean_spec_losses, _ = get_l0_freqs_loss_fvu(model, \"clean\", spec_tokens)\n",
    "\n",
    "    gsae_owt_l0, gsae_owt_freqs, gsae_owt_losses, gsae_owt_fvu  = get_l0_freqs_loss_fvu(model, [gsae], owt_tokens, num_tokens=num_tokens)\n",
    "    gsae_spec_l0, gsae_spec_freqs, gsae_spec_losses, gsae_spec_fvu = get_l0_freqs_loss_fvu(model, [gsae], spec_tokens, num_tokens=num_tokens)   \n",
    "\n",
    "    print(f\"clean owt loss = {clean_owt_losses.mean().item():.3f}\")\n",
    "    print(f\"gsae owt loss = {gsae_owt_losses.mean().item():.3f}\")\n",
    "    print(f\"gsae owt L0 = {gsae_owt_l0:.1f}\")\n",
    "    print(f\"gsae owt FVU = {gsae_owt_fvu:.2f}\")\n",
    "\n",
    "    print(f\"\\nclean spec loss = {clean_spec_losses.mean().item():.3f}\")\n",
    "    print(f\"gsae spec loss = {gsae_spec_losses.mean().item():.3f}\")\n",
    "    print(f\"gsae spec L0 = {gsae_spec_l0:.1f}\")\n",
    "    print(f\"gsae spec FVU = {gsae_spec_fvu:.2f}\")\n",
    "\n",
    "    print(f\"\\n\\ngetting pareto data for {subject}\\n\")\n",
    "    # get pareto data for SSAEs\n",
    "    ssae_owt_l0, ssae_owt_freqs, ssae_owt_scores, ssae_owt_fvu_recovered = sweep(model, [[gsae, ssae] for ssae in ssae_list], owt_tokens, gsae_owt_losses, clean_owt_losses, gsae_owt_fvu, num_tokens=num_tokens)\n",
    "    ssae_spec_l0, ssae_spec_freqs, ssae_spec_scores, ssae_spec_fvu_recovered = sweep(model, [[gsae, ssae] for ssae in ssae_list], spec_tokens, gsae_spec_losses, clean_spec_losses, gsae_spec_fvu, num_tokens=num_tokens)\n",
    "\n",
    "    # get pareto data for GSAE finetunes\n",
    "    gsae_ft_owt_l0, gsae_ft_owt_freqs, gsae_ft_owt_scores, gsae_ft_owt_fvu_recovered = sweep(model, [[gsae] for gsae in gsae_ft_list], owt_tokens, gsae_owt_losses, clean_owt_losses, gsae_owt_fvu, num_tokens=num_tokens)\n",
    "    gsae_ft_spec_l0, gsae_ft_spec_freqs, gsae_ft_spec_scores, gsae_ft_spec_fvu_recovered = sweep(model, [[gsae] for gsae in gsae_ft_list], spec_tokens, gsae_spec_losses, clean_spec_losses, gsae_spec_fvu, num_tokens=num_tokens)\n",
    "\n",
    "    # get pareto data for direct SAEs\n",
    "    direct_owt_l0, direct_owt_freqs, direct_owt_scores, direct_owt_fvu_recovered = sweep(model, [[sae] for sae in direct_sae_list], owt_tokens, gsae_owt_losses, clean_owt_losses, gsae_owt_fvu, num_tokens=num_tokens)\n",
    "    direct_spec_l0, direct_spec_freqs, direct_spec_scores, direct_spec_fvu_recovered = sweep(model, [[sae] for sae in direct_sae_list], spec_tokens, gsae_spec_losses, clean_spec_losses, gsae_spec_fvu, num_tokens=num_tokens)\n",
    "\n",
    "    get_freq_plots(ssae_owt_freqs, direct_owt_freqs, gsae_ft_owt_freqs,\n",
    "                    ssae_spec_freqs, direct_spec_freqs, gsae_ft_spec_freqs, \n",
    "                    subject)\n",
    "    \n",
    "    get_cossim_plots(gsae, gsae_ft_list, ssae_list, \n",
    "                     ssae_l1_list, gsae_ft_l1_list,                    \n",
    "                     subject)\n",
    "    \n",
    "    # save pareto data\n",
    "    gsae_ft_owt_data =  {\"l1\": gsae_ft_l1_list, \n",
    "                        \"l0\": gsae_ft_owt_l0, \n",
    "                        \"fvu\": gsae_ft_owt_fvu_recovered, \n",
    "                        \"scores\": gsae_ft_owt_scores}\n",
    "    ssae_owt_data = {\"l1\": ssae_l1_list,\n",
    "                    \"l0\": ssae_owt_l0,\n",
    "                    \"fvu\": ssae_owt_fvu_recovered,\n",
    "                    \"scores\": ssae_owt_scores}\n",
    "    direct_owt_data = {\"l1\": direct_sae_l1_list,\n",
    "                    \"l0\": direct_owt_l0,\n",
    "                    \"fvu\": direct_owt_fvu_recovered,\n",
    "                    \"scores\": direct_owt_scores}\n",
    "    gsae_ft_spec_data = {\"l1\": gsae_ft_l1_list,\n",
    "                        \"l0\": gsae_ft_spec_l0,\n",
    "                        \"fvu\": gsae_ft_spec_fvu_recovered,\n",
    "                        \"scores\": gsae_ft_spec_scores}\n",
    "    ssae_spec_data = {\"l1\": ssae_l1_list,\n",
    "                    \"l0\": ssae_spec_l0,\n",
    "                    \"fvu\": ssae_spec_fvu_recovered,\n",
    "                    \"scores\": ssae_spec_scores}\n",
    "    direct_spec_data = {\"l1\": direct_sae_l1_list,\n",
    "                    \"l0\": direct_spec_l0,\n",
    "                    \"fvu\": direct_spec_fvu_recovered,\n",
    "                    \"scores\": direct_spec_scores}\n",
    "    \n",
    "    return gsae_ft_owt_data, ssae_owt_data, direct_owt_data, gsae_ft_spec_data, ssae_spec_data, direct_spec_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "getting floor and ceiling losses for hs_bio_cleaned\n",
      "\n",
      "clean owt loss = 4.062\n",
      "gsae owt loss = 4.125\n",
      "gsae owt L0 = 21.2\n",
      "gsae owt FVU = 0.38\n",
      "\n",
      "clean spec loss = 3.391\n",
      "gsae spec loss = 3.766\n",
      "gsae spec L0 = 22.8\n",
      "gsae spec FVU = 0.45\n",
      "\n",
      "\n",
      "getting pareto data for hs_bio_cleaned\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [768, 125] at index 0 does not match the shape of the indexed tensor [128, 125] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_subject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 25\u001b[0m, in \u001b[0;36mrun_subject\u001b[0;34m(model, subject, num_tokens)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mgetting pareto data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# get pareto data for SSAEs\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m ssae_owt_l0, ssae_owt_freqs, ssae_owt_scores, ssae_owt_fvu_recovered \u001b[38;5;241m=\u001b[39m \u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgsae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssae\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mssae\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mssae_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowt_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgsae_owt_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_owt_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgsae_owt_fvu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m ssae_spec_l0, ssae_spec_freqs, ssae_spec_scores, ssae_spec_fvu_recovered \u001b[38;5;241m=\u001b[39m sweep(model, [[gsae, ssae] \u001b[38;5;28;01mfor\u001b[39;00m ssae \u001b[38;5;129;01min\u001b[39;00m ssae_list], spec_tokens, gsae_spec_losses, clean_spec_losses, gsae_spec_fvu, num_tokens\u001b[38;5;241m=\u001b[39mnum_tokens)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# get pareto data for GSAE finetunes\u001b[39;00m\n",
      "File \u001b[0;32m~/specialised-SAEs/sae_lens/jacob/analysis_fns.py:150\u001b[0m, in \u001b[0;36msweep\u001b[0;34m(model, list_of_sae_lists, tokens, ceiling_losses, clean_losses, ceiling_fvu, num_tokens)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# compute loss recovered score\u001b[39;00m\n\u001b[1;32m    148\u001b[0m mask \u001b[38;5;241m=\u001b[39m ceiling_losses \u001b[38;5;241m-\u001b[39m clean_losses \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;66;03m# ignore cases where there was no loss to recover in the first place\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m all_scores \u001b[38;5;241m=\u001b[39m (ceiling_losses[mask]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m \u001b[43mall_losses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m (ceiling_losses[mask]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m clean_losses[mask]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceiling_losses \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mceiling_losses\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatched_losses \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_losses\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [768, 125] at index 0 does not match the shape of the indexed tensor [128, 125] at index 0"
     ]
    }
   ],
   "source": [
    "run_subject(model, subject, num_tokens=20_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
