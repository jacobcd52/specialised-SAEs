The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.73s/it]
wandb: Currently logged in as: jacobcd52. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_053425-9qp9euzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_hs_bio_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_bio
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_bio/runs/9qp9euzh
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 171.59754943847656
New distances: 131.166748046875
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 19712.000 | L1 134144.000:   0%|          | 0/8192000 [01:01<?, ?it/s]100| main MSE Loss 19712.000 | L1 134144.000:   5%|▌         | 409600/8192000 [01:01<19:25, 6676.65it/s]100| main MSE Loss 19712.000 | L1 134144.000:   5%|▌         | 409600/8192000 [01:16<19:25, 6676.65it/s]200| main MSE Loss 15616.000 | L1 113152.000:   5%|▌         | 409600/8192000 [01:39<19:25, 6676.65it/s]200| main MSE Loss 15616.000 | L1 113152.000:  10%|█         | 819200/8192000 [01:39<14:15, 8615.65it/s]200| main MSE Loss 15616.000 | L1 113152.000:  10%|█         | 819200/8192000 [01:50<14:15, 8615.65it/s]300| main MSE Loss 13824.000 | L1 131072.000:  10%|█         | 819200/8192000 [02:19<14:15, 8615.65it/s]300| main MSE Loss 13824.000 | L1 131072.000:  15%|█▌        | 1228800/8192000 [02:19<12:31, 9270.58it/s]300| main MSE Loss 13824.000 | L1 131072.000:  15%|█▌        | 1228800/8192000 [02:30<12:31, 9270.58it/s]400| main MSE Loss 8640.000 | L1 152576.000:  15%|█▌        | 1228800/8192000 [02:58<12:31, 9270.58it/s] 400| main MSE Loss 8640.000 | L1 152576.000:  20%|██        | 1638400/8192000 [02:58<11:13, 9729.24it/s]400| main MSE Loss 8640.000 | L1 152576.000:  20%|██        | 1638400/8192000 [03:10<11:13, 9729.24it/s]500| main MSE Loss 9152.000 | L1 122880.000:  20%|██        | 1638400/8192000 [03:38<11:13, 9729.24it/s]500| main MSE Loss 9152.000 | L1 122880.000:  25%|██▌       | 2048000/8192000 [03:38<10:21, 9887.28it/s]500| main MSE Loss 9152.000 | L1 122880.000:  25%|██▌       | 2048000/8192000 [03:50<10:21, 9887.28it/s]600| main MSE Loss 9472.000 | L1 120832.000:  25%|██▌       | 2048000/8192000 [04:17<10:21, 9887.28it/s]600| main MSE Loss 9472.000 | L1 120832.000:  30%|███       | 2457600/8192000 [04:17<09:25, 10134.43it/s]600| main MSE Loss 9472.000 | L1 120832.000:  30%|███       | 2457600/8192000 [04:27<09:25, 10134.43it/s]700| main MSE Loss 6688.000 | L1 118784.000:  30%|███       | 2457600/8192000 [05:08<09:25, 10134.43it/s]700| main MSE Loss 6688.000 | L1 118784.000:  35%|███▌      | 2867200/8192000 [05:08<09:31, 9319.91it/s] 700| main MSE Loss 6688.000 | L1 118784.000:  35%|███▌      | 2867200/8192000 [05:20<09:31, 9319.91it/s]800| main MSE Loss 6656.000 | L1 125440.000:  35%|███▌      | 2867200/8192000 [05:45<09:31, 9319.91it/s]800| main MSE Loss 6656.000 | L1 125440.000:  40%|████      | 3276800/8192000 [05:45<08:23, 9767.51it/s]800| main MSE Loss 6656.000 | L1 125440.000:  40%|████      | 3276800/8192000 [05:57<08:23, 9767.51it/s]900| main MSE Loss 6176.000 | L1 78848.000:  40%|████      | 3276800/8192000 [06:43<08:23, 9767.51it/s] 900| main MSE Loss 6176.000 | L1 78848.000:  45%|████▌     | 3686400/8192000 [06:43<08:36, 8719.18it/s]900| main MSE Loss 6176.000 | L1 78848.000:  45%|████▌     | 3686400/8192000 [06:57<08:36, 8719.18it/s]1000| main MSE Loss 6240.000 | L1 65024.000:  45%|████▌     | 3686400/8192000 [07:30<08:36, 8719.18it/s]1000| main MSE Loss 6240.000 | L1 65024.000:  50%|█████     | 4096000/8192000 [07:30<07:47, 8757.41it/s]1000| main MSE Loss 6240.000 | L1 65024.000:  50%|█████     | 4096000/8192000 [07:47<07:47, 8757.41it/s]1100| main MSE Loss 6912.000 | L1 107520.000:  50%|█████     | 4096000/8192000 [08:19<07:47, 8757.41it/s]1100| main MSE Loss 6912.000 | L1 107520.000:  55%|█████▌    | 4505600/8192000 [08:19<07:06, 8635.89it/s]1100| main MSE Loss 6912.000 | L1 107520.000:  55%|█████▌    | 4505600/8192000 [08:30<07:06, 8635.89it/s]1200| main MSE Loss 6752.000 | L1 138240.000:  55%|█████▌    | 4505600/8192000 [09:03<07:06, 8635.89it/s]1200| main MSE Loss 6752.000 | L1 138240.000:  60%|██████    | 4915200/8192000 [09:03<06:12, 8788.52it/s]1200| main MSE Loss 6752.000 | L1 138240.000:  60%|██████    | 4915200/8192000 [09:17<06:12, 8788.52it/s]1300| main MSE Loss 6496.000 | L1 112640.000:  60%|██████    | 4915200/8192000 [10:02<06:12, 8788.52it/s]1300| main MSE Loss 6496.000 | L1 112640.000:  65%|██████▌   | 5324800/8192000 [10:02<05:51, 8164.94it/s]1300| main MSE Loss 6496.000 | L1 112640.000:  65%|██████▌   | 5324800/8192000 [10:17<05:51, 8164.94it/s]1400| main MSE Loss 6496.000 | L1 119296.000:  65%|██████▌   | 5324800/8192000 [10:44<05:51, 8164.94it/s]1400| main MSE Loss 6496.000 | L1 119296.000:  70%|███████   | 5734400/8192000 [10:44<04:46, 8578.27it/s]1400| main MSE Loss 6496.000 | L1 119296.000:  70%|███████   | 5734400/8192000 [10:57<04:46, 8578.27it/s]1500| main MSE Loss 6048.000 | L1 122880.000:  70%|███████   | 5734400/8192000 [11:28<04:46, 8578.27it/s]1500| main MSE Loss 6048.000 | L1 122880.000:  75%|███████▌  | 6144000/8192000 [11:28<03:53, 8758.97it/s]1500| main MSE Loss 6048.000 | L1 122880.000:  75%|███████▌  | 6144000/8192000 [11:40<03:53, 8758.97it/s]1600| main MSE Loss 6304.000 | L1 116224.000:  75%|███████▌  | 6144000/8192000 [12:18<03:53, 8758.97it/s]1600| main MSE Loss 6304.000 | L1 116224.000:  80%|████████  | 6553600/8192000 [12:18<03:10, 8598.85it/s]1600| main MSE Loss 6304.000 | L1 116224.000:  80%|████████  | 6553600/8192000 [12:30<03:10, 8598.85it/s]1700| main MSE Loss 6368.000 | L1 114688.000:  80%|████████  | 6553600/8192000 [13:15<03:10, 8598.85it/s]1700| main MSE Loss 6368.000 | L1 114688.000:  85%|████████▌ | 6963200/8192000 [13:15<02:31, 8133.46it/s]1700| main MSE Loss 6368.000 | L1 114688.000:  85%|████████▌ | 6963200/8192000 [13:27<02:31, 8133.46it/s]1800| main MSE Loss 5824.000 | L1 117248.000:  85%|████████▌ | 6963200/8192000 [13:58<02:31, 8133.46it/s]1800| main MSE Loss 5824.000 | L1 117248.000:  90%|█████████ | 7372800/8192000 [13:58<01:36, 8511.21it/s]1800| main MSE Loss 5824.000 | L1 117248.000:  90%|█████████ | 7372800/8192000 [14:10<01:36, 8511.21it/s]1900| main MSE Loss 5920.000 | L1 112640.000:  90%|█████████ | 7372800/8192000 [14:59<01:36, 8511.21it/s]1900| main MSE Loss 5920.000 | L1 112640.000:  95%|█████████▌| 7782400/8192000 [14:59<00:52, 7871.68it/s]1900| main MSE Loss 5920.000 | L1 112640.000:  95%|█████████▌| 7782400/8192000 [15:10<00:52, 7871.68it/s]2000| main MSE Loss 6016.000 | L1 115712.000:  95%|█████████▌| 7782400/8192000 [15:45<00:52, 7871.68it/s]2000| main MSE Loss 6016.000 | L1 115712.000: 100%|██████████| 8192000/8192000 [15:45<00:00, 8144.02it/s]2000| main MSE Loss 6016.000 | L1 115712.000: 100%|██████████| 8192000/8192000 [15:49<00:00, 8631.46it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.369 MB uploadedwandb: | 657.369 MB of 657.377 MB uploadedwandb: / 657.369 MB of 657.377 MB uploadedwandb: - 657.377 MB of 657.377 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▄▆▄▄▂▅▇▂▂▇▃▇▆▇▄▄▅▆▄▄▅▅▄▅▄▅▆▅▅▁█▆▂▆▄▄▆▂▅▅
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▄▃▂▁▂▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:                    metrics/main_loss ▂█▁▂
wandb:             metrics/main_output_norm ▇▇█▇▅██▃▃▇▃▇▆▇▄▃▅▆▄▄▅▅▃▄▄▅▅▅▄▁▇▆▂▆▄▄▅▂▅▅
wandb:             metrics/main_recons_loss █▃▁▁
wandb:                   metrics/main_score ▁███
wandb:           metrics/main_zero_abl_loss ▃█▁▁
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▅▅▅▅▂▆▇▂▂▇▂▇▆▇▅▄▅▆▄▄▅▅▄▅▄▅▆▆▅▁█▆▂▆▄▄▆▃▅▅
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▁▁▂▁▂▁▁▁▁▂▄▂▂▄▁▁▁▃▂▁▄▂▂▃▄▂▂▁▃▂▁█▆█▇▄▂▂
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 15680.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 254.976
wandb:                 losses/main_mse_loss 5792.0
wandb:                  losses/overall_loss 148480.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 7.82495
wandb:                    metrics/main_loss 2.28281
wandb:             metrics/main_output_norm 272.0
wandb:             metrics/main_recons_loss 2.45
wandb:                   metrics/main_score 0.74492
wandb:           metrics/main_zero_abl_loss 2.9375
wandb:  metrics/mean_log10_feature_sparsity -3.57283
wandb:           metrics/target_output_norm 296.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 1.0013
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_hs_bio_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_bio/runs/9qp9euzh
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_bio
wandb: Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_053425-9qp9euzh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
Reached end of dataset. Resetting iterator.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.63M/689M [00:00<00:53, 12.8MB/s]sae_weights.safetensors:   0%|          | 2.92M/689M [00:00<02:02, 5.62MB/s]sae_weights.safetensors:   1%|          | 6.73M/689M [00:00<00:49, 13.7MB/s]sae_weights.safetensors:   2%|▏         | 11.4M/689M [00:00<00:30, 21.9MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:46, 14.5MB/s]sae_weights.safetensors:   3%|▎         | 21.7M/689M [00:01<00:31, 21.4MB/s]sae_weights.safetensors:   4%|▎         | 25.1M/689M [00:01<00:39, 17.0MB/s]sae_weights.safetensors:   4%|▍         | 27.8M/689M [00:01<00:36, 18.0MB/s]sae_weights.safetensors:   4%|▍         | 30.3M/689M [00:01<00:34, 19.0MB/s]sae_weights.safetensors:   5%|▍         | 32.8M/689M [00:02<01:03, 10.4MB/s]sae_weights.safetensors:   5%|▌         | 37.8M/689M [00:02<00:43, 14.8MB/s]sae_weights.safetensors:   6%|▌         | 40.2M/689M [00:02<00:41, 15.8MB/s]sae_weights.safetensors:   6%|▋         | 43.1M/689M [00:02<00:43, 14.9MB/s]sae_weights.safetensors:   7%|▋         | 45.1M/689M [00:02<00:41, 15.5MB/s]sae_weights.safetensors:   7%|▋         | 48.0M/689M [00:03<01:07, 9.43MB/s]sae_weights.safetensors:   8%|▊         | 54.5M/689M [00:03<00:44, 14.3MB/s]sae_weights.safetensors:   8%|▊         | 56.5M/689M [00:03<00:44, 14.2MB/s]sae_weights.safetensors:   9%|▊         | 59.8M/689M [00:04<00:40, 15.4MB/s]sae_weights.safetensors:   9%|▉         | 61.6M/689M [00:04<00:39, 15.8MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:04<01:06, 9.43MB/s]sae_weights.safetensors:  10%|█         | 69.1M/689M [00:04<00:43, 14.1MB/s]sae_weights.safetensors:  10%|█         | 71.2M/689M [00:04<00:42, 14.5MB/s]sae_weights.safetensors:  11%|█         | 73.2M/689M [00:05<00:42, 14.6MB/s]sae_weights.safetensors:  11%|█         | 77.0M/689M [00:05<00:38, 16.0MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:05<01:03, 9.66MB/s]sae_weights.safetensors:  12%|█▏        | 85.1M/689M [00:06<00:42, 14.1MB/s]sae_weights.safetensors:  13%|█▎        | 88.3M/689M [00:06<00:39, 15.2MB/s]sae_weights.safetensors:  13%|█▎        | 90.5M/689M [00:06<00:38, 15.8MB/s]sae_weights.safetensors:  13%|█▎        | 92.5M/689M [00:06<00:37, 15.9MB/s]sae_weights.safetensors:  14%|█▍        | 95.0M/689M [00:06<00:33, 17.6MB/s]sae_weights.safetensors:  14%|█▍        | 97.1M/689M [00:07<01:04, 9.13MB/s]sae_weights.safetensors:  15%|█▍        | 102M/689M [00:07<00:43, 13.6MB/s] sae_weights.safetensors:  16%|█▌        | 107M/689M [00:07<00:40, 14.4MB/s]sae_weights.safetensors:  16%|█▌        | 109M/689M [00:07<00:39, 14.8MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:08<01:02, 9.31MB/s]sae_weights.safetensors:  17%|█▋        | 119M/689M [00:08<00:40, 14.1MB/s]sae_weights.safetensors:  18%|█▊        | 121M/689M [00:08<00:40, 14.2MB/s]sae_weights.safetensors:  18%|█▊        | 123M/689M [00:08<00:37, 15.1MB/s]sae_weights.safetensors:  18%|█▊        | 126M/689M [00:08<00:36, 15.3MB/s]sae_weights.safetensors:  19%|█▊        | 128M/689M [00:09<00:58, 9.63MB/s]sae_weights.safetensors:  19%|█▉        | 134M/689M [00:09<00:35, 15.6MB/s]sae_weights.safetensors:  20%|█▉        | 137M/689M [00:09<00:34, 15.9MB/s]sae_weights.safetensors:  20%|██        | 139M/689M [00:09<00:37, 14.5MB/s]sae_weights.safetensors:  21%|██        | 143M/689M [00:10<00:31, 17.3MB/s]sae_weights.safetensors:  21%|██        | 145M/689M [00:10<00:55, 9.84MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:11<00:26, 20.0MB/s]sae_weights.safetensors:  24%|██▍       | 165M/689M [00:11<00:23, 22.8MB/s]sae_weights.safetensors:  24%|██▍       | 168M/689M [00:11<00:22, 23.3MB/s]sae_weights.safetensors:  25%|██▍       | 171M/689M [00:11<00:26, 19.8MB/s]sae_weights.safetensors:  25%|██▌       | 173M/689M [00:11<00:25, 19.9MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:12<00:45, 11.2MB/s]sae_weights.safetensors:  27%|██▋       | 184M/689M [00:12<00:28, 17.6MB/s]sae_weights.safetensors:  27%|██▋       | 188M/689M [00:12<00:32, 15.2MB/s]sae_weights.safetensors:  28%|██▊       | 190M/689M [00:12<00:30, 16.2MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:13<00:48, 10.3MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:14<00:30, 15.7MB/s]sae_weights.safetensors:  31%|███▏      | 215M/689M [00:14<00:24, 19.2MB/s]sae_weights.safetensors:  32%|███▏      | 218M/689M [00:14<00:24, 19.4MB/s]sae_weights.safetensors:  32%|███▏      | 220M/689M [00:14<00:26, 17.6MB/s]sae_weights.safetensors:  32%|███▏      | 223M/689M [00:14<00:25, 18.4MB/s]sae_weights.safetensors:  33%|███▎      | 225M/689M [00:15<00:40, 11.5MB/s]sae_weights.safetensors:  33%|███▎      | 229M/689M [00:15<00:30, 14.9MB/s]sae_weights.safetensors:  34%|███▍      | 235M/689M [00:15<00:29, 15.6MB/s]sae_weights.safetensors:  34%|███▍      | 237M/689M [00:15<00:29, 15.4MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:16<00:41, 10.8MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:16<00:19, 22.6MB/s]sae_weights.safetensors:  38%|███▊      | 261M/689M [00:16<00:16, 26.3MB/s]sae_weights.safetensors:  38%|███▊      | 265M/689M [00:16<00:15, 26.8MB/s]sae_weights.safetensors:  39%|███▉      | 268M/689M [00:17<00:20, 20.3MB/s]sae_weights.safetensors:  39%|███▉      | 271M/689M [00:17<00:19, 21.7MB/s]sae_weights.safetensors:  40%|███▉      | 274M/689M [00:17<00:36, 11.4MB/s]sae_weights.safetensors:  40%|████      | 279M/689M [00:18<00:28, 14.6MB/s]sae_weights.safetensors:  41%|████      | 282M/689M [00:18<00:24, 16.8MB/s]sae_weights.safetensors:  41%|████▏     | 285M/689M [00:18<00:27, 15.0MB/s]sae_weights.safetensors:  42%|████▏     | 287M/689M [00:18<00:24, 16.4MB/s]sae_weights.safetensors:  42%|████▏     | 289M/689M [00:19<00:39, 10.1MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:19<00:18, 21.2MB/s]sae_weights.safetensors:  45%|████▌     | 313M/689M [00:19<00:12, 30.1MB/s]sae_weights.safetensors:  46%|████▌     | 318M/689M [00:20<00:18, 20.2MB/s]sae_weights.safetensors:  47%|████▋     | 321M/689M [00:20<00:26, 14.0MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:20<00:15, 22.1MB/s]sae_weights.safetensors:  50%|████▉     | 344M/689M [00:21<00:12, 27.7MB/s]sae_weights.safetensors:  51%|█████     | 348M/689M [00:21<00:15, 21.9MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:21<00:15, 21.8MB/s]sae_weights.safetensors:  51%|█████▏    | 355M/689M [00:22<00:22, 14.6MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:22<00:15, 20.4MB/s]sae_weights.safetensors:  54%|█████▍    | 375M/689M [00:22<00:12, 25.2MB/s]sae_weights.safetensors:  55%|█████▍    | 378M/689M [00:22<00:13, 23.5MB/s]sae_weights.safetensors:  55%|█████▌    | 382M/689M [00:23<00:14, 20.7MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:23<00:25, 12.1MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:24<00:13, 20.9MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:24<00:10, 27.0MB/s]sae_weights.safetensors:  61%|██████▏   | 423M/689M [00:24<00:08, 31.4MB/s]sae_weights.safetensors:  62%|██████▏   | 427M/689M [00:24<00:10, 24.4MB/s]sae_weights.safetensors:  62%|██████▏   | 431M/689M [00:25<00:10, 25.0MB/s]sae_weights.safetensors:  63%|██████▎   | 434M/689M [00:25<00:16, 15.7MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:25<00:10, 23.9MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:26<00:07, 31.2MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:26<00:06, 34.2MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:27<00:04, 38.8MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:27<00:04, 39.2MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:27<00:03, 41.5MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:28<00:03, 39.6MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:28<00:03, 38.9MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:28<00:02, 41.5MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:29<00:02, 43.4MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:29<00:01, 45.9MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:30<00:01, 42.1MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:30<00:01, 42.7MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:30<00:00, 42.3MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:31<00:00, 43.5MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:31<00:00, 41.7MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:31<00:00, 21.7MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_055315-5z5p9b55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_hs_phys_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_phys
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_phys/runs/5z5p9b55
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 165.28761291503906
New distances: 130.42274475097656
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 25344.000 | L1 130560.000:   0%|          | 0/8192000 [01:05<?, ?it/s]100| main MSE Loss 25344.000 | L1 130560.000:   5%|▌         | 409600/8192000 [01:05<20:50, 6224.11it/s]100| main MSE Loss 25344.000 | L1 130560.000:   5%|▌         | 409600/8192000 [01:16<20:50, 6224.11it/s]200| main MSE Loss 21120.000 | L1 139264.000:   5%|▌         | 409600/8192000 [01:47<20:50, 6224.11it/s]200| main MSE Loss 21120.000 | L1 139264.000:  10%|█         | 819200/8192000 [01:47<15:31, 7915.83it/s]200| main MSE Loss 21120.000 | L1 139264.000:  10%|█         | 819200/8192000 [02:00<15:31, 7915.83it/s]300| main MSE Loss 17024.000 | L1 122368.000:  10%|█         | 819200/8192000 [02:29<15:31, 7915.83it/s]300| main MSE Loss 17024.000 | L1 122368.000:  15%|█▌        | 1228800/8192000 [02:29<13:21, 8686.10it/s]300| main MSE Loss 17024.000 | L1 122368.000:  15%|█▌        | 1228800/8192000 [02:40<13:21, 8686.10it/s]400| main MSE Loss 11392.000 | L1 109568.000:  15%|█▌        | 1228800/8192000 [03:12<13:21, 8686.10it/s]400| main MSE Loss 11392.000 | L1 109568.000:  20%|██        | 1638400/8192000 [03:12<12:07, 9011.32it/s]400| main MSE Loss 11392.000 | L1 109568.000:  20%|██        | 1638400/8192000 [03:27<12:07, 9011.32it/s]500| main MSE Loss 10112.000 | L1 112640.000:  20%|██        | 1638400/8192000 [03:58<12:07, 9011.32it/s]500| main MSE Loss 10112.000 | L1 112640.000:  25%|██▌       | 2048000/8192000 [03:58<11:25, 8962.70it/s]500| main MSE Loss 10112.000 | L1 112640.000:  25%|██▌       | 2048000/8192000 [04:10<11:25, 8962.70it/s]600| main MSE Loss 10496.000 | L1 123904.000:  25%|██▌       | 2048000/8192000 [04:41<11:25, 8962.70it/s]600| main MSE Loss 10496.000 | L1 123904.000:  30%|███       | 2457600/8192000 [04:41<10:29, 9113.19it/s]600| main MSE Loss 10496.000 | L1 123904.000:  30%|███       | 2457600/8192000 [04:57<10:29, 9113.19it/s]700| main MSE Loss 9344.000 | L1 122880.000:  30%|███       | 2457600/8192000 [05:38<10:29, 9113.19it/s] 700| main MSE Loss 9344.000 | L1 122880.000:  35%|███▌      | 2867200/8192000 [05:38<10:33, 8402.22it/s]700| main MSE Loss 9344.000 | L1 122880.000:  35%|███▌      | 2867200/8192000 [05:50<10:33, 8402.22it/s]800| main MSE Loss 9152.000 | L1 104960.000:  35%|███▌      | 2867200/8192000 [06:26<10:33, 8402.22it/s]800| main MSE Loss 9152.000 | L1 104960.000:  40%|████      | 3276800/8192000 [06:26<09:44, 8415.76it/s]800| main MSE Loss 9152.000 | L1 104960.000:  40%|████      | 3276800/8192000 [06:37<09:44, 8415.76it/s]900| main MSE Loss 8960.000 | L1 146432.000:  40%|████      | 3276800/8192000 [07:28<09:44, 8415.76it/s]900| main MSE Loss 8960.000 | L1 146432.000:  45%|████▌     | 3686400/8192000 [07:28<09:40, 7755.72it/s]900| main MSE Loss 8960.000 | L1 146432.000:  45%|████▌     | 3686400/8192000 [07:40<09:40, 7755.72it/s]1000| main MSE Loss 9344.000 | L1 131072.000:  45%|████▌     | 3686400/8192000 [08:12<09:40, 7755.72it/s]1000| main MSE Loss 9344.000 | L1 131072.000:  50%|█████     | 4096000/8192000 [08:12<08:20, 8185.00it/s]1000| main MSE Loss 9344.000 | L1 131072.000:  50%|█████     | 4096000/8192000 [08:27<08:20, 8185.00it/s]1100| main MSE Loss 8704.000 | L1 112640.000:  50%|█████     | 4096000/8192000 [08:59<08:20, 8185.00it/s]1100| main MSE Loss 8704.000 | L1 112640.000:  55%|█████▌    | 4505600/8192000 [08:59<07:22, 8336.08it/s]1100| main MSE Loss 8704.000 | L1 112640.000:  55%|█████▌    | 4505600/8192000 [09:10<07:22, 8336.08it/s]1200| main MSE Loss 10112.000 | L1 125952.000:  55%|█████▌    | 4505600/8192000 [09:45<07:22, 8336.08it/s]1200| main MSE Loss 10112.000 | L1 125952.000:  60%|██████    | 4915200/8192000 [09:45<06:25, 8511.00it/s]1200| main MSE Loss 10112.000 | L1 125952.000:  60%|██████    | 4915200/8192000 [09:57<06:25, 8511.00it/s]1300| main MSE Loss 9856.000 | L1 148480.000:  60%|██████    | 4915200/8192000 [10:42<06:25, 8511.00it/s] 1300| main MSE Loss 9856.000 | L1 148480.000:  65%|██████▌   | 5324800/8192000 [10:42<05:55, 8068.29it/s]1300| main MSE Loss 9856.000 | L1 148480.000:  65%|██████▌   | 5324800/8192000 [10:57<05:55, 8068.29it/s]1400| main MSE Loss 10624.000 | L1 142336.000:  65%|██████▌   | 5324800/8192000 [11:30<05:55, 8068.29it/s]1400| main MSE Loss 10624.000 | L1 142336.000:  70%|███████   | 5734400/8192000 [11:30<04:58, 8220.34it/s]1400| main MSE Loss 10624.000 | L1 142336.000:  70%|███████   | 5734400/8192000 [11:40<04:58, 8220.34it/s]1500| main MSE Loss 9472.000 | L1 114176.000:  70%|███████   | 5734400/8192000 [12:16<04:58, 8220.34it/s] 1500| main MSE Loss 9472.000 | L1 114176.000:  75%|███████▌  | 6144000/8192000 [12:16<04:04, 8375.80it/s]1500| main MSE Loss 9472.000 | L1 114176.000:  75%|███████▌  | 6144000/8192000 [12:27<04:04, 8375.80it/s]1600| main MSE Loss 8768.000 | L1 110592.000:  75%|███████▌  | 6144000/8192000 [13:01<04:04, 8375.80it/s]1600| main MSE Loss 8768.000 | L1 110592.000:  80%|████████  | 6553600/8192000 [13:01<03:10, 8580.75it/s]1600| main MSE Loss 8768.000 | L1 110592.000:  80%|████████  | 6553600/8192000 [13:17<03:10, 8580.75it/s]1700| main MSE Loss 8960.000 | L1 133120.000:  80%|████████  | 6553600/8192000 [13:57<03:10, 8580.75it/s]1700| main MSE Loss 8960.000 | L1 133120.000:  85%|████████▌ | 6963200/8192000 [13:57<02:29, 8195.33it/s]1700| main MSE Loss 8960.000 | L1 133120.000:  85%|████████▌ | 6963200/8192000 [14:07<02:29, 8195.33it/s]1800| main MSE Loss 8896.000 | L1 116736.000:  85%|████████▌ | 6963200/8192000 [14:42<02:29, 8195.33it/s]1800| main MSE Loss 8896.000 | L1 116736.000:  90%|█████████ | 7372800/8192000 [14:42<01:37, 8442.16it/s]1800| main MSE Loss 8896.000 | L1 116736.000:  90%|█████████ | 7372800/8192000 [14:57<01:37, 8442.16it/s]1900| main MSE Loss 8640.000 | L1 144384.000:  90%|█████████ | 7372800/8192000 [15:36<01:37, 8442.16it/s]1900| main MSE Loss 8640.000 | L1 144384.000:  95%|█████████▌| 7782400/8192000 [15:36<00:50, 8174.76it/s]1900| main MSE Loss 8640.000 | L1 144384.000:  95%|█████████▌| 7782400/8192000 [15:47<00:50, 8174.76it/s]2000| main MSE Loss 8896.000 | L1 137216.000:  95%|█████████▌| 7782400/8192000 [16:19<00:50, 8174.76it/s]2000| main MSE Loss 8896.000 | L1 137216.000: 100%|██████████| 8192000/8192000 [16:19<00:00, 8500.51it/s]2000| main MSE Loss 8896.000 | L1 137216.000: 100%|██████████| 8192000/8192000 [16:23<00:00, 8331.11it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.361 MB of 657.361 MB uploadedwandb: / 657.381 MB of 657.381 MB uploadedwandb: - 657.381 MB of 657.381 MB uploadedwandb: \ 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▄█▃▂▄▄▃▄▃▄▄▄▄▅▁▇▃▄▃▃▂▃▄▁▃▅▂▂▃▂▂▅▂▃▅▂▆▆▁▅
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▂▁▁▃▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂
wandb:                    metrics/main_loss ▂█▁▄
wandb:             metrics/main_output_norm ▄█▇▆▇▆▄▄▃▄▄▄▄▅▁▇▃▄▃▃▂▃▄▁▃▅▂▂▃▃▂▅▂▃▅▂▆▆▁▅
wandb:             metrics/main_recons_loss █▄▁▂
wandb:                   metrics/main_score ▁█▇█
wandb:           metrics/main_zero_abl_loss ▄█▁▅
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▃▇▅▃▅▅▃▄▄▅▄▄▄▆▁█▄▅▃▄▂▃▄▁▃▅▂▂▃▃▃▅▂▄▆▂▇▇▁▆
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▁▃▁▁▁▁▁▁▁▁▂▄▁▁▁▁▁▁▁▇▅▂▁▁▁▁▂▁▂█▅▁▁▁▂▁▃▁
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 14592.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 280.576
wandb:                 losses/main_mse_loss 9152.0
wandb:                  losses/overall_loss 163840.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 65.67993
wandb:                    metrics/main_loss 2.51719
wandb:             metrics/main_output_norm 328.0
wandb:             metrics/main_recons_loss 2.69531
wandb:                   metrics/main_score 0.73398
wandb:           metrics/main_zero_abl_loss 3.1875
wandb:  metrics/mean_log10_feature_sparsity -2.78251
wandb:           metrics/target_output_norm 326.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 0.12999
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_hs_phys_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_phys/runs/5z5p9b55
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_phys
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_055315-5z5p9b55/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
Reached end of dataset. Resetting iterator.
Reached end of dataset. Resetting iterator.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.42M/689M [00:00<01:03, 10.9MB/s]sae_weights.safetensors:   0%|          | 2.51M/689M [00:00<02:11, 5.21MB/s]sae_weights.safetensors:   0%|          | 3.21M/689M [00:00<02:07, 5.40MB/s]sae_weights.safetensors:   1%|          | 5.64M/689M [00:00<01:08, 10.0MB/s]sae_weights.safetensors:   2%|▏         | 10.8M/689M [00:00<00:33, 20.3MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:43, 15.5MB/s]sae_weights.safetensors:   3%|▎         | 18.6M/689M [00:01<00:43, 15.3MB/s]sae_weights.safetensors:   3%|▎         | 20.4M/689M [00:01<00:55, 11.9MB/s]sae_weights.safetensors:   3%|▎         | 22.0M/689M [00:01<00:55, 12.1MB/s]sae_weights.safetensors:   4%|▎         | 24.5M/689M [00:01<00:46, 14.3MB/s]sae_weights.safetensors:   4%|▍         | 29.4M/689M [00:02<00:31, 21.1MB/s]sae_weights.safetensors:   5%|▍         | 32.0M/689M [00:02<00:47, 13.9MB/s]sae_weights.safetensors:   7%|▋         | 48.0M/689M [00:02<00:23, 27.0MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:03<00:17, 36.4MB/s]sae_weights.safetensors:  10%|▉         | 67.9M/689M [00:03<00:17, 34.9MB/s]sae_weights.safetensors:  10%|█         | 71.3M/689M [00:03<00:23, 25.8MB/s]sae_weights.safetensors:  11%|█         | 74.9M/689M [00:03<00:23, 25.8MB/s]sae_weights.safetensors:  12%|█▏        | 79.3M/689M [00:03<00:21, 28.5MB/s]sae_weights.safetensors:  12%|█▏        | 82.4M/689M [00:04<00:32, 18.7MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:04<00:29, 19.9MB/s]sae_weights.safetensors:  15%|█▍        | 101M/689M [00:04<00:27, 21.7MB/s] sae_weights.safetensors:  15%|█▌        | 104M/689M [00:05<00:27, 21.1MB/s]sae_weights.safetensors:  15%|█▌        | 106M/689M [00:05<00:28, 20.7MB/s]sae_weights.safetensors:  16%|█▌        | 108M/689M [00:05<00:28, 20.1MB/s]sae_weights.safetensors:  16%|█▌        | 110M/689M [00:05<00:28, 20.0MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:05<00:57, 10.0MB/s]sae_weights.safetensors:  19%|█▊        | 128M/689M [00:06<00:26, 20.8MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:06<00:19, 27.8MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:07<00:17, 30.2MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:07<00:14, 34.8MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:08<00:13, 35.8MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:08<00:11, 41.9MB/s]sae_weights.safetensors:  31%|███▏      | 217M/689M [00:08<00:10, 44.9MB/s]sae_weights.safetensors:  32%|███▏      | 221M/689M [00:08<00:15, 30.8MB/s]sae_weights.safetensors:  33%|███▎      | 225M/689M [00:09<00:22, 20.5MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:09<00:18, 24.4MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:10<00:15, 28.7MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:10<00:12, 32.5MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:11<00:11, 35.8MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:11<00:10, 38.3MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:11<00:09, 40.7MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:12<00:10, 34.8MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:12<00:09, 35.1MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:13<00:09, 35.7MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:13<00:08, 35.4MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:14<00:07, 36.6MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:14<00:07, 38.2MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:14<00:06, 37.7MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:15<00:06, 37.9MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:15<00:05, 38.1MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:16<00:05, 40.5MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:16<00:04, 40.5MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:16<00:04, 43.1MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:17<00:03, 42.9MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:17<00:03, 45.0MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:17<00:02, 44.3MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:18<00:02, 42.7MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:18<00:02, 42.6MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:18<00:01, 43.0MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:19<00:01, 45.3MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:19<00:01, 46.7MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:19<00:00, 45.5MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:20<00:00, 42.4MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:20<00:00, 43.3MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:20<00:00, 32.8MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.47s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_061213-7t4gtx1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_hs_math_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_math
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_math/runs/7t4gtx1e
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 166.37335205078125
New distances: 127.95796966552734
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 19072.000 | L1 122368.000:   0%|          | 0/8192000 [01:08<?, ?it/s]100| main MSE Loss 19072.000 | L1 122368.000:   5%|▌         | 409600/8192000 [01:08<21:39, 5989.60it/s]100| main MSE Loss 19072.000 | L1 122368.000:   5%|▌         | 409600/8192000 [01:20<21:39, 5989.60it/s]200| main MSE Loss 17664.000 | L1 125952.000:   5%|▌         | 409600/8192000 [01:53<21:39, 5989.60it/s]200| main MSE Loss 17664.000 | L1 125952.000:  10%|█         | 819200/8192000 [01:53<16:26, 7474.10it/s]200| main MSE Loss 17664.000 | L1 125952.000:  10%|█         | 819200/8192000 [02:10<16:26, 7474.10it/s]300| main MSE Loss 13952.000 | L1 114688.000:  10%|█         | 819200/8192000 [02:38<16:26, 7474.10it/s]300| main MSE Loss 13952.000 | L1 114688.000:  15%|█▌        | 1228800/8192000 [02:38<14:11, 8174.50it/s]300| main MSE Loss 13952.000 | L1 114688.000:  15%|█▌        | 1228800/8192000 [02:50<14:11, 8174.50it/s]400| main MSE Loss 10560.000 | L1 142336.000:  15%|█▌        | 1228800/8192000 [03:23<14:11, 8174.50it/s]400| main MSE Loss 10560.000 | L1 142336.000:  20%|██        | 1638400/8192000 [03:23<12:50, 8502.96it/s]400| main MSE Loss 10560.000 | L1 142336.000:  20%|██        | 1638400/8192000 [03:40<12:50, 8502.96it/s]500| main MSE Loss 8160.000 | L1 102400.000:  20%|██        | 1638400/8192000 [04:07<12:50, 8502.96it/s] 500| main MSE Loss 8160.000 | L1 102400.000:  25%|██▌       | 2048000/8192000 [04:07<11:43, 8738.08it/s]500| main MSE Loss 8160.000 | L1 102400.000:  25%|██▌       | 2048000/8192000 [04:20<11:43, 8738.08it/s]600| main MSE Loss 8160.000 | L1 112640.000:  25%|██▌       | 2048000/8192000 [04:54<11:43, 8738.08it/s]600| main MSE Loss 8160.000 | L1 112640.000:  30%|███       | 2457600/8192000 [04:54<10:56, 8741.45it/s]600| main MSE Loss 8160.000 | L1 112640.000:  30%|███       | 2457600/8192000 [05:10<10:56, 8741.45it/s]700| main MSE Loss 8960.000 | L1 132096.000:  30%|███       | 2457600/8192000 [05:51<10:56, 8741.45it/s]700| main MSE Loss 8960.000 | L1 132096.000:  35%|███▌      | 2867200/8192000 [05:51<10:53, 8154.16it/s]700| main MSE Loss 8960.000 | L1 132096.000:  35%|███▌      | 2867200/8192000 [06:03<10:53, 8154.16it/s]800| main MSE Loss 8512.000 | L1 95232.000:  35%|███▌      | 2867200/8192000 [06:38<10:53, 8154.16it/s] 800| main MSE Loss 8512.000 | L1 95232.000:  40%|████      | 3276800/8192000 [06:38<09:48, 8355.92it/s]800| main MSE Loss 8512.000 | L1 95232.000:  40%|████      | 3276800/8192000 [06:50<09:48, 8355.92it/s]900| main MSE Loss 8128.000 | L1 116224.000:  40%|████      | 3276800/8192000 [07:36<09:48, 8355.92it/s]900| main MSE Loss 8128.000 | L1 116224.000:  45%|████▌     | 3686400/8192000 [07:36<09:30, 7903.48it/s]900| main MSE Loss 8128.000 | L1 116224.000:  45%|████▌     | 3686400/8192000 [07:50<09:30, 7903.48it/s]1000| main MSE Loss 8096.000 | L1 153600.000:  45%|████▌     | 3686400/8192000 [08:19<09:30, 7903.48it/s]1000| main MSE Loss 8096.000 | L1 153600.000:  50%|█████     | 4096000/8192000 [08:19<08:11, 8336.03it/s]1000| main MSE Loss 8096.000 | L1 153600.000:  50%|█████     | 4096000/8192000 [08:30<08:11, 8336.03it/s]1100| main MSE Loss 7968.000 | L1 112640.000:  50%|█████     | 4096000/8192000 [09:04<08:11, 8336.03it/s]1100| main MSE Loss 7968.000 | L1 112640.000:  55%|█████▌    | 4505600/8192000 [09:04<07:10, 8571.52it/s]1100| main MSE Loss 7968.000 | L1 112640.000:  55%|█████▌    | 4505600/8192000 [09:20<07:10, 8571.52it/s]1200| main MSE Loss 8256.000 | L1 130048.000:  55%|█████▌    | 4505600/8192000 [09:48<07:10, 8571.52it/s]1200| main MSE Loss 8256.000 | L1 130048.000:  60%|██████    | 4915200/8192000 [09:48<06:14, 8755.44it/s]1200| main MSE Loss 8256.000 | L1 130048.000:  60%|██████    | 4915200/8192000 [10:00<06:14, 8755.44it/s]1300| main MSE Loss 8512.000 | L1 114688.000:  60%|██████    | 4915200/8192000 [10:44<06:14, 8755.44it/s]1300| main MSE Loss 8512.000 | L1 114688.000:  65%|██████▌   | 5324800/8192000 [10:44<05:46, 8269.66it/s]1300| main MSE Loss 8512.000 | L1 114688.000:  65%|██████▌   | 5324800/8192000 [11:00<05:46, 8269.66it/s]1400| main MSE Loss 8448.000 | L1 94720.000:  65%|██████▌   | 5324800/8192000 [11:29<05:46, 8269.66it/s] 1400| main MSE Loss 8448.000 | L1 94720.000:  70%|███████   | 5734400/8192000 [11:29<04:49, 8503.32it/s]1400| main MSE Loss 8448.000 | L1 94720.000:  70%|███████   | 5734400/8192000 [11:40<04:49, 8503.32it/s]1500| main MSE Loss 8256.000 | L1 107008.000:  70%|███████   | 5734400/8192000 [12:13<04:49, 8503.32it/s]1500| main MSE Loss 8256.000 | L1 107008.000:  75%|███████▌  | 6144000/8192000 [12:13<03:53, 8758.15it/s]1500| main MSE Loss 8256.000 | L1 107008.000:  75%|███████▌  | 6144000/8192000 [12:23<03:53, 8758.15it/s]1600| main MSE Loss 7904.000 | L1 77824.000:  75%|███████▌  | 6144000/8192000 [12:55<03:53, 8758.15it/s] 1600| main MSE Loss 7904.000 | L1 77824.000:  80%|████████  | 6553600/8192000 [12:55<03:01, 9008.19it/s]1600| main MSE Loss 7904.000 | L1 77824.000:  80%|████████  | 6553600/8192000 [13:10<03:01, 9008.19it/s]1700| main MSE Loss 8320.000 | L1 139264.000:  80%|████████  | 6553600/8192000 [13:53<03:01, 9008.19it/s]1700| main MSE Loss 8320.000 | L1 139264.000:  85%|████████▌ | 6963200/8192000 [13:53<02:27, 8344.24it/s]1700| main MSE Loss 8320.000 | L1 139264.000:  85%|████████▌ | 6963200/8192000 [14:03<02:27, 8344.24it/s]1800| main MSE Loss 8192.000 | L1 130048.000:  85%|████████▌ | 6963200/8192000 [14:37<02:27, 8344.24it/s]1800| main MSE Loss 8192.000 | L1 130048.000:  90%|█████████ | 7372800/8192000 [14:37<01:35, 8605.94it/s]1800| main MSE Loss 8192.000 | L1 130048.000:  90%|█████████ | 7372800/8192000 [14:50<01:35, 8605.94it/s]1900| main MSE Loss 7584.000 | L1 133120.000:  90%|█████████ | 7372800/8192000 [15:34<01:35, 8605.94it/s]1900| main MSE Loss 7584.000 | L1 133120.000:  95%|█████████▌| 7782400/8192000 [15:34<00:50, 8123.49it/s]1900| main MSE Loss 7584.000 | L1 133120.000:  95%|█████████▌| 7782400/8192000 [15:50<00:50, 8123.49it/s]2000| main MSE Loss 7360.000 | L1 120320.000:  95%|█████████▌| 7782400/8192000 [16:17<00:50, 8123.49it/s]2000| main MSE Loss 7360.000 | L1 120320.000: 100%|██████████| 8192000/8192000 [16:17<00:00, 8505.74it/s]2000| main MSE Loss 7360.000 | L1 120320.000: 100%|██████████| 8192000/8192000 [16:22<00:00, 8341.82it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.381 MB of 657.390 MB uploadedwandb: / 657.397 MB of 657.397 MB uploadedwandb: - 657.397 MB of 657.397 MB uploadedwandb: \ 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▃▄▂▅▁▂▃▂▂▅▂▁▃▃▄▃▃▃▄▃▂▄▃▄▄▃█▄▄▂▄▃▂▁▂▄▄▄▂▂
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 ▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    metrics/main_loss ▄█▁▆
wandb:             metrics/main_output_norm ▅▆▅█▃▄▅▃▃▆▃▁▄▄▅▄▃▄▆▄▂▅▄▅▄▄█▅▅▂▅▄▃▁▂▅▄▅▃▃
wandb:             metrics/main_recons_loss █▄▁▄
wandb:                   metrics/main_score ▁███
wandb:           metrics/main_zero_abl_loss ▄▇▁█
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▄▅▄█▂▄▅▂▃█▃▁▅▅▆▅▄▅▇▅▃▇▅▆▅▅▆▆▆▃▇▅▃▁▂▆▅▇▃▃
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▂▅▄▂▂▃▄█▄▄▄▁▆
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 13888.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 220.16
wandb:                 losses/main_mse_loss 7424.0
wandb:                  losses/overall_loss 132096.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 7.54468
wandb:                    metrics/main_loss 2.42969
wandb:             metrics/main_output_norm 258.0
wandb:             metrics/main_recons_loss 2.75469
wandb:                   metrics/main_score 0.66953
wandb:           metrics/main_zero_abl_loss 3.39688
wandb:  metrics/mean_log10_feature_sparsity -2.50828
wandb:           metrics/target_output_norm 258.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 14.07053
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_hs_math_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_math/runs/7t4gtx1e
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-hs_math
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_061213-7t4gtx1e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.55M/689M [00:00<01:00, 11.4MB/s]sae_weights.safetensors:   0%|          | 2.69M/689M [00:00<02:05, 5.49MB/s]sae_weights.safetensors:   1%|          | 3.66M/689M [00:00<01:44, 6.56MB/s]sae_weights.safetensors:   1%|          | 5.14M/689M [00:00<01:23, 8.19MB/s]sae_weights.safetensors:   2%|▏         | 10.8M/689M [00:00<00:34, 19.8MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:43, 15.4MB/s]sae_weights.safetensors:   5%|▍         | 32.0M/689M [00:01<00:22, 29.2MB/s]sae_weights.safetensors:   5%|▌         | 36.8M/689M [00:01<00:22, 28.9MB/s]sae_weights.safetensors:   6%|▌         | 39.7M/689M [00:01<00:29, 22.0MB/s]sae_weights.safetensors:   6%|▌         | 42.2M/689M [00:02<00:30, 21.4MB/s]sae_weights.safetensors:   7%|▋         | 45.1M/689M [00:02<00:28, 22.4MB/s]sae_weights.safetensors:   7%|▋         | 48.0M/689M [00:02<00:45, 14.1MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:02<00:22, 28.4MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:03<00:17, 35.3MB/s]sae_weights.safetensors:  12%|█▏        | 84.1M/689M [00:03<00:17, 34.6MB/s]sae_weights.safetensors:  13%|█▎        | 87.6M/689M [00:03<00:23, 25.6MB/s]sae_weights.safetensors:  13%|█▎        | 90.4M/689M [00:03<00:24, 24.7MB/s]sae_weights.safetensors:  14%|█▎        | 93.4M/689M [00:03<00:23, 25.2MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:04<00:52, 11.2MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:05<00:29, 19.6MB/s] sae_weights.safetensors:  19%|█▊        | 128M/689M [00:05<00:22, 25.2MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:05<00:16, 32.6MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:06<00:14, 35.5MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:07<00:17, 29.4MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:07<00:15, 32.8MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:07<00:13, 36.3MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:08<00:11, 40.6MB/s]sae_weights.safetensors:  33%|███▎      | 228M/689M [00:08<00:11, 39.7MB/s]sae_weights.safetensors:  34%|███▎      | 233M/689M [00:08<00:20, 22.7MB/s]sae_weights.safetensors:  34%|███▍      | 236M/689M [00:09<00:20, 22.0MB/s]sae_weights.safetensors:  35%|███▍      | 239M/689M [00:09<00:19, 23.7MB/s]sae_weights.safetensors:  35%|███▌      | 242M/689M [00:09<00:26, 16.7MB/s]sae_weights.safetensors:  35%|███▌      | 245M/689M [00:09<00:26, 16.8MB/s]sae_weights.safetensors:  36%|███▌      | 247M/689M [00:09<00:28, 15.5MB/s]sae_weights.safetensors:  36%|███▌      | 249M/689M [00:10<00:31, 14.2MB/s]sae_weights.safetensors:  37%|███▋      | 252M/689M [00:10<00:27, 15.8MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:10<00:21, 20.2MB/s]sae_weights.safetensors:  37%|███▋      | 258M/689M [00:10<00:33, 12.8MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:11<00:18, 22.5MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:11<00:15, 26.2MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:12<00:11, 32.1MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:12<00:12, 29.4MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:13<00:10, 32.7MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:13<00:09, 36.9MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:13<00:08, 38.9MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:14<00:07, 39.3MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:14<00:06, 43.2MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:14<00:06, 44.4MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:15<00:05, 45.3MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:15<00:05, 43.0MB/s]sae_weights.safetensors:  66%|██████▌   | 456M/689M [00:15<00:04, 47.1MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:16<00:06, 34.4MB/s]sae_weights.safetensors:  68%|██████▊   | 469M/689M [00:16<00:06, 34.8MB/s]sae_weights.safetensors:  69%|██████▊   | 473M/689M [00:16<00:08, 25.8MB/s]sae_weights.safetensors:  69%|██████▉   | 477M/689M [00:16<00:08, 25.7MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:17<00:13, 15.8MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:17<00:07, 24.4MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:18<00:06, 29.3MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:18<00:04, 35.0MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:18<00:03, 37.3MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:19<00:03, 35.1MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:19<00:02, 38.6MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:20<00:02, 35.1MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:20<00:02, 37.3MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:20<00:01, 37.3MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:21<00:01, 36.4MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:21<00:00, 36.8MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:22<00:00, 38.0MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:22<00:00, 39.8MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:22<00:00, 30.3MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_063045-dutxphwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_college_bio_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_bio
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_bio/runs/dutxphwq
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 169.55718994140625
New distances: 131.35707092285156
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 19712.000 | L1 132096.000:   0%|          | 0/8192000 [01:01<?, ?it/s]100| main MSE Loss 19712.000 | L1 132096.000:   5%|▌         | 409600/8192000 [01:01<19:19, 6714.66it/s]100| main MSE Loss 19712.000 | L1 132096.000:   5%|▌         | 409600/8192000 [01:11<19:19, 6714.66it/s]200| main MSE Loss 16896.000 | L1 115712.000:   5%|▌         | 409600/8192000 [01:41<19:19, 6714.66it/s]200| main MSE Loss 16896.000 | L1 115712.000:  10%|█         | 819200/8192000 [01:41<14:37, 8403.60it/s]200| main MSE Loss 16896.000 | L1 115712.000:  10%|█         | 819200/8192000 [01:51<14:37, 8403.60it/s]300| main MSE Loss 14528.000 | L1 95232.000:  10%|█         | 819200/8192000 [02:20<14:37, 8403.60it/s] 300| main MSE Loss 14528.000 | L1 95232.000:  15%|█▌        | 1228800/8192000 [02:20<12:33, 9239.64it/s]300| main MSE Loss 14528.000 | L1 95232.000:  15%|█▌        | 1228800/8192000 [02:31<12:33, 9239.64it/s]400| main MSE Loss 9344.000 | L1 155648.000:  15%|█▌        | 1228800/8192000 [02:58<12:33, 9239.64it/s]400| main MSE Loss 9344.000 | L1 155648.000:  20%|██        | 1638400/8192000 [02:58<11:13, 9730.98it/s]400| main MSE Loss 9344.000 | L1 155648.000:  20%|██        | 1638400/8192000 [03:11<11:13, 9730.98it/s]500| main MSE Loss 9280.000 | L1 132096.000:  20%|██        | 1638400/8192000 [03:38<11:13, 9730.98it/s]500| main MSE Loss 9280.000 | L1 132096.000:  25%|██▌       | 2048000/8192000 [03:38<10:15, 9978.47it/s]500| main MSE Loss 9280.000 | L1 132096.000:  25%|██▌       | 2048000/8192000 [03:48<10:15, 9978.47it/s]600| main MSE Loss 7808.000 | L1 127488.000:  25%|██▌       | 2048000/8192000 [04:17<10:15, 9978.47it/s]600| main MSE Loss 7808.000 | L1 127488.000:  30%|███       | 2457600/8192000 [04:17<09:27, 10106.55it/s]600| main MSE Loss 7808.000 | L1 127488.000:  30%|███       | 2457600/8192000 [04:29<09:27, 10106.55it/s]700| main MSE Loss 9344.000 | L1 117248.000:  30%|███       | 2457600/8192000 [05:11<09:27, 10106.55it/s]700| main MSE Loss 9344.000 | L1 117248.000:  35%|███▌      | 2867200/8192000 [05:11<09:42, 9146.41it/s] 700| main MSE Loss 9344.000 | L1 117248.000:  35%|███▌      | 2867200/8192000 [05:21<09:42, 9146.41it/s]800| main MSE Loss 8704.000 | L1 128000.000:  35%|███▌      | 2867200/8192000 [05:52<09:42, 9146.41it/s]800| main MSE Loss 8704.000 | L1 128000.000:  40%|████      | 3276800/8192000 [05:52<08:44, 9364.89it/s]800| main MSE Loss 8704.000 | L1 128000.000:  40%|████      | 3276800/8192000 [06:09<08:44, 9364.89it/s]900| main MSE Loss 8256.000 | L1 137216.000:  40%|████      | 3276800/8192000 [06:44<08:44, 9364.89it/s]900| main MSE Loss 8256.000 | L1 137216.000:  45%|████▌     | 3686400/8192000 [06:44<08:28, 8863.12it/s]900| main MSE Loss 8256.000 | L1 137216.000:  45%|████▌     | 3686400/8192000 [06:59<08:28, 8863.12it/s]1000| main MSE Loss 7872.000 | L1 138240.000:  45%|████▌     | 3686400/8192000 [07:25<08:28, 8863.12it/s]1000| main MSE Loss 7872.000 | L1 138240.000:  50%|█████     | 4096000/8192000 [07:25<07:25, 9203.11it/s]1000| main MSE Loss 7872.000 | L1 138240.000:  50%|█████     | 4096000/8192000 [07:39<07:25, 9203.11it/s]1100| main MSE Loss 8320.000 | L1 115200.000:  50%|█████     | 4096000/8192000 [08:07<07:25, 9203.11it/s]1100| main MSE Loss 8320.000 | L1 115200.000:  55%|█████▌    | 4505600/8192000 [08:07<06:34, 9345.22it/s]1100| main MSE Loss 8320.000 | L1 115200.000:  55%|█████▌    | 4505600/8192000 [08:19<06:34, 9345.22it/s]1200| main MSE Loss 8640.000 | L1 103936.000:  55%|█████▌    | 4505600/8192000 [08:48<06:34, 9345.22it/s]1200| main MSE Loss 8640.000 | L1 103936.000:  60%|██████    | 4915200/8192000 [08:48<05:45, 9497.47it/s]1200| main MSE Loss 8640.000 | L1 103936.000:  60%|██████    | 4915200/8192000 [08:59<05:45, 9497.47it/s]1300| main MSE Loss 8064.000 | L1 129024.000:  60%|██████    | 4915200/8192000 [09:42<05:45, 9497.47it/s]1300| main MSE Loss 8064.000 | L1 129024.000:  65%|██████▌   | 5324800/8192000 [09:42<05:24, 8824.64it/s]1300| main MSE Loss 8064.000 | L1 129024.000:  65%|██████▌   | 5324800/8192000 [09:59<05:24, 8824.64it/s]1400| main MSE Loss 8256.000 | L1 153600.000:  65%|██████▌   | 5324800/8192000 [10:25<05:24, 8824.64it/s]1400| main MSE Loss 8256.000 | L1 153600.000:  70%|███████   | 5734400/8192000 [10:25<04:32, 9027.71it/s]1400| main MSE Loss 8256.000 | L1 153600.000:  70%|███████   | 5734400/8192000 [10:39<04:32, 9027.71it/s]1500| main MSE Loss 7360.000 | L1 102400.000:  70%|███████   | 5734400/8192000 [11:06<04:32, 9027.71it/s]1500| main MSE Loss 7360.000 | L1 102400.000:  75%|███████▌  | 6144000/8192000 [11:06<03:40, 9287.52it/s]1500| main MSE Loss 7360.000 | L1 102400.000:  75%|███████▌  | 6144000/8192000 [11:19<03:40, 9287.52it/s]1600| main MSE Loss 8320.000 | L1 145408.000:  75%|███████▌  | 6144000/8192000 [11:50<03:40, 9287.52it/s]1600| main MSE Loss 8320.000 | L1 145408.000:  80%|████████  | 6553600/8192000 [11:50<02:56, 9301.67it/s]1600| main MSE Loss 8320.000 | L1 145408.000:  80%|████████  | 6553600/8192000 [12:02<02:56, 9301.67it/s]1700| main MSE Loss 7872.000 | L1 120320.000:  80%|████████  | 6553600/8192000 [12:44<02:56, 9301.67it/s]1700| main MSE Loss 7872.000 | L1 120320.000:  85%|████████▌ | 6963200/8192000 [12:44<02:20, 8744.62it/s]1700| main MSE Loss 7872.000 | L1 120320.000:  85%|████████▌ | 6963200/8192000 [12:59<02:20, 8744.62it/s]1800| main MSE Loss 8032.000 | L1 95744.000:  85%|████████▌ | 6963200/8192000 [13:24<02:20, 8744.62it/s] 1800| main MSE Loss 8032.000 | L1 95744.000:  90%|█████████ | 7372800/8192000 [13:24<01:30, 9099.88it/s]1800| main MSE Loss 8032.000 | L1 95744.000:  90%|█████████ | 7372800/8192000 [13:39<01:30, 9099.88it/s]1900| main MSE Loss 7808.000 | L1 83968.000:  90%|█████████ | 7372800/8192000 [14:18<01:30, 9099.88it/s]1900| main MSE Loss 7808.000 | L1 83968.000:  95%|█████████▌| 7782400/8192000 [14:18<00:47, 8606.36it/s]1900| main MSE Loss 7808.000 | L1 83968.000:  95%|█████████▌| 7782400/8192000 [14:29<00:47, 8606.36it/s]2000| main MSE Loss 7808.000 | L1 146432.000:  95%|█████████▌| 7782400/8192000 [14:58<00:47, 8606.36it/s]2000| main MSE Loss 7808.000 | L1 146432.000: 100%|██████████| 8192000/8192000 [14:58<00:00, 9070.59it/s]2000| main MSE Loss 7808.000 | L1 146432.000: 100%|██████████| 8192000/8192000 [15:01<00:00, 9082.20it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.361 MB of 657.361 MB uploadedwandb: / 657.381 MB of 657.381 MB uploadedwandb: - 657.385 MB of 657.397 MB uploadedwandb: \ 657.385 MB of 657.397 MB uploadedwandb: | 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▆▇▁▅▄▄▆▃▄▇▇▁▂▅▃▄▄▂▃▂▄▂▃▆▃▂▆▆▆▅▃▄▇▂▄█▂▃▇▅
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    metrics/main_loss ▁▄█▁
wandb:             metrics/main_output_norm ▅▇▄▇▆▆▇▄▄▆▆▁▂▄▃▄▄▂▃▂▃▂▃▅▃▂▆▆▆▅▃▄▆▂▄█▂▃▇▅
wandb:             metrics/main_recons_loss █▂▃▁
wandb:                   metrics/main_score ▁███
wandb:           metrics/main_zero_abl_loss ▁▄█▁
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▄▅▂▅▄▅▆▃▄▇▇▁▂▅▃▄▄▃▄▂▄▂▃▅▃▂▆▆▆▅▃▄▇▂▄█▃▃▇▅
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▁▁▁▁▁▁▁▁▁▂▃▂▁▁▂▂▂▃▅▁▁▃▁▂▆▁▂▂▂▃▄▃▁▁▂▃█▃
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 14592.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 274.432
wandb:                 losses/main_mse_loss 7872.0
wandb:                  losses/overall_loss 159744.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 11.91699
wandb:                    metrics/main_loss 2.67813
wandb:             metrics/main_output_norm 312.0
wandb:             metrics/main_recons_loss 2.87344
wandb:                   metrics/main_score 0.73008
wandb:           metrics/main_zero_abl_loss 3.39844
wandb:  metrics/mean_log10_feature_sparsity -3.21229
wandb:           metrics/target_output_norm 310.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 2.7793
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_college_bio_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_bio/runs/dutxphwq
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_bio
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_063045-dutxphwq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.48M/689M [00:00<01:09, 9.96MB/s]sae_weights.safetensors:   0%|          | 2.48M/689M [00:00<02:24, 4.77MB/s]sae_weights.safetensors:   1%|          | 3.73M/689M [00:00<01:47, 6.36MB/s]sae_weights.safetensors:   1%|          | 5.20M/689M [00:00<01:21, 8.41MB/s]sae_weights.safetensors:   2%|▏         | 10.5M/689M [00:00<00:34, 19.7MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:50, 13.3MB/s]sae_weights.safetensors:   3%|▎         | 18.6M/689M [00:01<00:45, 14.7MB/s]sae_weights.safetensors:   3%|▎         | 20.6M/689M [00:01<00:59, 11.3MB/s]sae_weights.safetensors:   3%|▎         | 22.3M/689M [00:01<00:58, 11.4MB/s]sae_weights.safetensors:   4%|▎         | 24.8M/689M [00:02<00:49, 13.5MB/s]sae_weights.safetensors:   4%|▍         | 30.2M/689M [00:02<00:31, 21.0MB/s]sae_weights.safetensors:   5%|▍         | 33.0M/689M [00:02<00:49, 13.3MB/s]sae_weights.safetensors:   5%|▌         | 35.1M/689M [00:02<00:49, 13.2MB/s]sae_weights.safetensors:   5%|▌         | 37.0M/689M [00:02<00:57, 11.4MB/s]sae_weights.safetensors:   6%|▌         | 38.5M/689M [00:03<00:56, 11.5MB/s]sae_weights.safetensors:   6%|▌         | 41.1M/689M [00:03<00:46, 14.0MB/s]sae_weights.safetensors:   7%|▋         | 46.0M/689M [00:03<00:30, 20.8MB/s]sae_weights.safetensors:   7%|▋         | 48.6M/689M [00:03<00:59, 10.8MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:04<00:34, 18.2MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:04<00:25, 24.3MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:05<00:20, 29.1MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:05<00:15, 36.5MB/s] sae_weights.safetensors:  19%|█▊        | 128M/689M [00:06<00:16, 33.5MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:06<00:15, 35.8MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:07<00:17, 29.9MB/s]sae_weights.safetensors:  24%|██▍       | 168M/689M [00:07<00:15, 34.0MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:07<00:20, 25.6MB/s]sae_weights.safetensors:  26%|██▋       | 182M/689M [00:08<00:18, 27.3MB/s]sae_weights.safetensors:  27%|██▋       | 186M/689M [00:08<00:23, 21.7MB/s]sae_weights.safetensors:  27%|██▋       | 189M/689M [00:08<00:22, 22.3MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:09<00:31, 15.9MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:09<00:19, 24.6MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:09<00:15, 30.6MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:10<00:14, 32.1MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:10<00:12, 34.1MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:11<00:11, 37.0MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:11<00:10, 39.0MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:16<00:46, 8.21MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:16<00:33, 11.2MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:17<00:24, 14.6MB/s]sae_weights.safetensors:  50%|████▉     | 344M/689M [00:17<00:20, 16.7MB/s]sae_weights.safetensors:  51%|█████     | 348M/689M [00:17<00:22, 15.0MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:18<00:28, 11.8MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:19<00:18, 17.7MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:19<00:13, 23.3MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:19<00:09, 29.3MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:20<00:08, 32.3MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:20<00:07, 35.7MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:20<00:06, 39.1MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:21<00:05, 41.1MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:21<00:04, 42.3MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:21<00:04, 43.5MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:22<00:04, 39.1MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:22<00:03, 41.7MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:23<00:03, 41.8MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:23<00:03, 36.8MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:23<00:03, 37.0MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:24<00:02, 36.2MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:24<00:02, 34.5MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:25<00:01, 39.8MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:25<00:01, 40.5MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:25<00:00, 43.9MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:26<00:00, 43.8MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:26<00:00, 45.0MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:26<00:00, 25.7MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.29s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_064816-xeza19d0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_college_phys_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_phys
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_phys/runs/xeza19d0
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 169.9019775390625
New distances: 131.03955078125
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 20992.000 | L1 93184.000:   0%|          | 0/8192000 [01:06<?, ?it/s]100| main MSE Loss 20992.000 | L1 93184.000:   5%|▌         | 409600/8192000 [01:06<20:58, 6183.07it/s]100| main MSE Loss 20992.000 | L1 93184.000:   5%|▌         | 409600/8192000 [01:19<20:58, 6183.07it/s]200| main MSE Loss 15936.000 | L1 132096.000:   5%|▌         | 409600/8192000 [01:47<20:58, 6183.07it/s]200| main MSE Loss 15936.000 | L1 132096.000:  10%|█         | 819200/8192000 [01:47<15:29, 7933.15it/s]200| main MSE Loss 15936.000 | L1 132096.000:  10%|█         | 819200/8192000 [01:59<15:29, 7933.15it/s]300| main MSE Loss 13184.000 | L1 95744.000:  10%|█         | 819200/8192000 [02:32<15:29, 7933.15it/s] 300| main MSE Loss 13184.000 | L1 95744.000:  15%|█▌        | 1228800/8192000 [02:32<13:43, 8457.42it/s]300| main MSE Loss 13184.000 | L1 95744.000:  15%|█▌        | 1228800/8192000 [02:49<13:43, 8457.42it/s]400| main MSE Loss 13248.000 | L1 120832.000:  15%|█▌        | 1228800/8192000 [03:14<13:43, 8457.42it/s]400| main MSE Loss 13248.000 | L1 120832.000:  20%|██        | 1638400/8192000 [03:14<12:16, 8901.69it/s]400| main MSE Loss 13248.000 | L1 120832.000:  20%|██        | 1638400/8192000 [03:29<12:16, 8901.69it/s]500| main MSE Loss 12416.000 | L1 146432.000:  20%|██        | 1638400/8192000 [03:56<12:16, 8901.69it/s]500| main MSE Loss 12416.000 | L1 146432.000:  25%|██▌       | 2048000/8192000 [03:56<11:05, 9225.92it/s]500| main MSE Loss 12416.000 | L1 146432.000:  25%|██▌       | 2048000/8192000 [04:09<11:05, 9225.92it/s]600| main MSE Loss 12800.000 | L1 124416.000:  25%|██▌       | 2048000/8192000 [04:37<11:05, 9225.92it/s]600| main MSE Loss 12800.000 | L1 124416.000:  30%|███       | 2457600/8192000 [04:37<10:08, 9429.16it/s]600| main MSE Loss 12800.000 | L1 124416.000:  30%|███       | 2457600/8192000 [04:49<10:08, 9429.16it/s]700| main MSE Loss 12992.000 | L1 113152.000:  30%|███       | 2457600/8192000 [05:31<10:08, 9429.16it/s]700| main MSE Loss 12992.000 | L1 113152.000:  35%|███▌      | 2867200/8192000 [05:31<10:10, 8725.19it/s]700| main MSE Loss 12992.000 | L1 113152.000:  35%|███▌      | 2867200/8192000 [05:42<10:10, 8725.19it/s]800| main MSE Loss 9344.000 | L1 135168.000:  35%|███▌      | 2867200/8192000 [06:13<10:10, 8725.19it/s] 800| main MSE Loss 9344.000 | L1 135168.000:  40%|████      | 3276800/8192000 [06:13<09:02, 9064.72it/s]800| main MSE Loss 9344.000 | L1 135168.000:  40%|████      | 3276800/8192000 [06:29<09:02, 9064.72it/s]900| main MSE Loss 7936.000 | L1 142336.000:  40%|████      | 3276800/8192000 [07:05<09:02, 9064.72it/s]900| main MSE Loss 7936.000 | L1 142336.000:  45%|████▌     | 3686400/8192000 [07:05<08:41, 8634.06it/s]900| main MSE Loss 7936.000 | L1 142336.000:  45%|████▌     | 3686400/8192000 [07:19<08:41, 8634.06it/s]1000| main MSE Loss 7872.000 | L1 121344.000:  45%|████▌     | 3686400/8192000 [07:48<08:41, 8634.06it/s]1000| main MSE Loss 7872.000 | L1 121344.000:  50%|█████     | 4096000/8192000 [07:48<07:39, 8915.73it/s]1000| main MSE Loss 7872.000 | L1 121344.000:  50%|█████     | 4096000/8192000 [07:59<07:39, 8915.73it/s]1100| main MSE Loss 8640.000 | L1 126464.000:  50%|█████     | 4096000/8192000 [08:30<07:39, 8915.73it/s]1100| main MSE Loss 8640.000 | L1 126464.000:  55%|█████▌    | 4505600/8192000 [08:30<06:43, 9143.88it/s]1100| main MSE Loss 8640.000 | L1 126464.000:  55%|█████▌    | 4505600/8192000 [08:42<06:43, 9143.88it/s]1200| main MSE Loss 7776.000 | L1 114688.000:  55%|█████▌    | 4505600/8192000 [09:12<06:43, 9143.88it/s]1200| main MSE Loss 7776.000 | L1 114688.000:  60%|██████    | 4915200/8192000 [09:12<05:51, 9326.20it/s]1200| main MSE Loss 7776.000 | L1 114688.000:  60%|██████    | 4915200/8192000 [09:30<05:51, 9326.20it/s]1300| main MSE Loss 9536.000 | L1 149504.000:  60%|██████    | 4915200/8192000 [10:07<05:51, 9326.20it/s]1300| main MSE Loss 9536.000 | L1 149504.000:  65%|██████▌   | 5324800/8192000 [10:07<05:30, 8669.11it/s]1300| main MSE Loss 9536.000 | L1 149504.000:  65%|██████▌   | 5324800/8192000 [10:20<05:30, 8669.11it/s]1400| main MSE Loss 8192.000 | L1 121344.000:  65%|██████▌   | 5324800/8192000 [10:46<05:30, 8669.11it/s]1400| main MSE Loss 8192.000 | L1 121344.000:  70%|███████   | 5734400/8192000 [10:46<04:28, 9153.41it/s]1400| main MSE Loss 8192.000 | L1 121344.000:  70%|███████   | 5734400/8192000 [11:00<04:28, 9153.41it/s]1500| main MSE Loss 7744.000 | L1 108544.000:  70%|███████   | 5734400/8192000 [11:26<04:28, 9153.41it/s]1500| main MSE Loss 7744.000 | L1 108544.000:  75%|███████▌  | 6144000/8192000 [11:26<03:36, 9447.73it/s]1500| main MSE Loss 7744.000 | L1 108544.000:  75%|███████▌  | 6144000/8192000 [11:40<03:36, 9447.73it/s]1600| main MSE Loss 8160.000 | L1 134144.000:  75%|███████▌  | 6144000/8192000 [12:08<03:36, 9447.73it/s]1600| main MSE Loss 8160.000 | L1 134144.000:  80%|████████  | 6553600/8192000 [12:08<02:51, 9532.06it/s]1600| main MSE Loss 8160.000 | L1 134144.000:  80%|████████  | 6553600/8192000 [12:20<02:51, 9532.06it/s]1700| main MSE Loss 7392.000 | L1 113152.000:  80%|████████  | 6553600/8192000 [13:00<02:51, 9532.06it/s]1700| main MSE Loss 7392.000 | L1 113152.000:  85%|████████▌ | 6963200/8192000 [13:00<02:17, 8942.18it/s]1700| main MSE Loss 7392.000 | L1 113152.000:  85%|████████▌ | 6963200/8192000 [13:12<02:17, 8942.18it/s]1800| main MSE Loss 6688.000 | L1 126464.000:  85%|████████▌ | 6963200/8192000 [13:41<02:17, 8942.18it/s]1800| main MSE Loss 6688.000 | L1 126464.000:  90%|█████████ | 7372800/8192000 [13:41<01:28, 9269.57it/s]1800| main MSE Loss 6688.000 | L1 126464.000:  90%|█████████ | 7372800/8192000 [13:52<01:28, 9269.57it/s]1900| main MSE Loss 6912.000 | L1 141312.000:  90%|█████████ | 7372800/8192000 [14:36<01:28, 9269.57it/s]1900| main MSE Loss 6912.000 | L1 141312.000:  95%|█████████▌| 7782400/8192000 [14:36<00:47, 8623.93it/s]1900| main MSE Loss 6912.000 | L1 141312.000:  95%|█████████▌| 7782400/8192000 [14:50<00:47, 8623.93it/s]2000| main MSE Loss 8320.000 | L1 128000.000:  95%|█████████▌| 7782400/8192000 [15:16<00:47, 8623.93it/s]2000| main MSE Loss 8320.000 | L1 128000.000: 100%|██████████| 8192000/8192000 [15:16<00:00, 9060.15it/s]2000| main MSE Loss 8320.000 | L1 128000.000: 100%|██████████| 8192000/8192000 [15:20<00:00, 8902.24it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.381 MB of 657.397 MB uploadedwandb: / 657.381 MB of 657.397 MB uploadedwandb: - 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▇▆▄▅▃▂▆▇▇█▅▄▁▂▆▁▇▇▅▇▄▄▄▅▅▇▃▅▃▄▄▆▅▇▅█▄▅▇▆
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    metrics/main_loss ▁▇▆█
wandb:             metrics/main_output_norm ▇▆▇▆▄▃▇▇▇█▆▅▂▃▇▁▆▆▅▆▃▃▃▄▄▆▃▄▂▄▄▅▄▆▄▇▃▄▆▆
wandb:             metrics/main_recons_loss █▃▁▂
wandb:                   metrics/main_score ▁▇██
wandb:           metrics/main_zero_abl_loss ▁▆▅█
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▇▅▅▅▃▂▆▇▇█▅▄▂▂▆▁▆▇▅▇▄▄▃▅▅▇▃▅▃▄▄▆▅▇▅█▄▅▇▆
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▃▄▅▅▂▄▃▅▅█▄
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 15168.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 290.816
wandb:                 losses/main_mse_loss 7840.0
wandb:                  losses/overall_loss 168960.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 9.50146
wandb:                    metrics/main_loss 2.8625
wandb:             metrics/main_output_norm 326.0
wandb:             metrics/main_recons_loss 3.09844
wandb:                   metrics/main_score 0.71758
wandb:           metrics/main_zero_abl_loss 3.69531
wandb:  metrics/mean_log10_feature_sparsity -3.14138
wandb:           metrics/target_output_norm 332.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 17.79134
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_college_phys_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_phys/runs/xeza19d0
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_phys
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_064816-xeza19d0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 582k/689M [00:00<04:15, 2.69MB/s]sae_weights.safetensors:   0%|          | 852k/689M [00:00<05:04, 2.26MB/s]sae_weights.safetensors:   1%|          | 3.53M/689M [00:00<01:29, 7.70MB/s]sae_weights.safetensors:   1%|          | 4.27M/689M [00:00<01:40, 6.81MB/s]sae_weights.safetensors:   1%|          | 4.92M/689M [00:00<01:53, 6.02MB/s]sae_weights.safetensors:   1%|          | 6.09M/689M [00:00<01:39, 6.89MB/s]sae_weights.safetensors:   1%|          | 8.14M/689M [00:01<01:08, 9.89MB/s]sae_weights.safetensors:   2%|▏         | 12.8M/689M [00:01<00:35, 18.9MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:55, 12.2MB/s]sae_weights.safetensors:   3%|▎         | 18.5M/689M [00:01<00:50, 13.4MB/s]sae_weights.safetensors:   3%|▎         | 20.2M/689M [00:02<01:00, 11.0MB/s]sae_weights.safetensors:   3%|▎         | 22.0M/689M [00:02<00:58, 11.3MB/s]sae_weights.safetensors:   4%|▎         | 24.5M/689M [00:02<00:48, 13.7MB/s]sae_weights.safetensors:   4%|▍         | 28.9M/689M [00:02<00:33, 19.6MB/s]sae_weights.safetensors:   5%|▍         | 32.0M/689M [00:02<00:48, 13.6MB/s]sae_weights.safetensors:   5%|▌         | 35.8M/689M [00:02<00:41, 15.7MB/s]sae_weights.safetensors:   5%|▌         | 37.8M/689M [00:03<00:41, 15.5MB/s]sae_weights.safetensors:   6%|▌         | 39.7M/689M [00:03<00:46, 14.1MB/s]sae_weights.safetensors:   6%|▌         | 43.0M/689M [00:03<00:37, 17.2MB/s]sae_weights.safetensors:   7%|▋         | 47.1M/689M [00:03<00:29, 21.8MB/s]sae_weights.safetensors:   7%|▋         | 49.6M/689M [00:03<00:55, 11.4MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:04<00:27, 22.6MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:04<00:19, 31.7MB/s]sae_weights.safetensors:  12%|█▏        | 83.4M/689M [00:04<00:22, 27.0MB/s]sae_weights.safetensors:  12%|█▏        | 86.1M/689M [00:05<00:25, 23.4MB/s]sae_weights.safetensors:  13%|█▎        | 88.5M/689M [00:05<00:31, 18.9MB/s]sae_weights.safetensors:  13%|█▎        | 90.4M/689M [00:05<00:34, 17.4MB/s]sae_weights.safetensors:  13%|█▎        | 93.0M/689M [00:05<00:33, 18.0MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:06<00:52, 11.4MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:06<00:25, 22.7MB/s] sae_weights.safetensors:  19%|█▊        | 128M/689M [00:06<00:18, 30.2MB/s]sae_weights.safetensors:  19%|█▉        | 131M/689M [00:07<00:19, 28.3MB/s]sae_weights.safetensors:  19%|█▉        | 134M/689M [00:07<00:21, 26.2MB/s]sae_weights.safetensors:  20%|█▉        | 137M/689M [00:07<00:23, 23.5MB/s]sae_weights.safetensors:  20%|██        | 139M/689M [00:07<00:35, 15.3MB/s]sae_weights.safetensors:  20%|██        | 141M/689M [00:07<00:33, 16.4MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:08<00:50, 10.7MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:08<00:25, 21.1MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:09<00:18, 28.5MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:09<00:15, 32.3MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:09<00:13, 36.1MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:10<00:12, 38.7MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:10<00:12, 37.1MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:12<00:19, 22.2MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:12<00:16, 25.0MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:13<00:14, 27.2MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:13<00:12, 31.6MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:13<00:10, 34.2MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:14<00:11, 31.6MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:15<00:12, 27.5MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:15<00:10, 31.8MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:15<00:08, 37.2MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:16<00:07, 38.1MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:16<00:07, 35.7MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:17<00:07, 36.7MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:17<00:05, 40.6MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:17<00:05, 40.6MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:17<00:04, 44.4MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:18<00:04, 46.1MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:18<00:03, 44.3MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:19<00:03, 42.5MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:19<00:04, 30.1MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:20<00:03, 33.3MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:20<00:03, 34.9MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:21<00:02, 37.7MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:21<00:02, 39.6MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:21<00:01, 41.6MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:22<00:01, 31.2MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:23<00:01, 32.2MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:23<00:00, 36.3MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:23<00:00, 34.6MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:24<00:00, 28.6MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_070605-yz8a8xkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_college_math_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_math
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_math/runs/yz8a8xkm
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 168.7258758544922
New distances: 125.52436828613281
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 18688.000 | L1 110080.000:   0%|          | 0/8192000 [01:00<?, ?it/s]100| main MSE Loss 18688.000 | L1 110080.000:   5%|▌         | 409600/8192000 [01:00<19:18, 6716.84it/s]100| main MSE Loss 18688.000 | L1 110080.000:   5%|▌         | 409600/8192000 [01:11<19:18, 6716.84it/s]200| main MSE Loss 15488.000 | L1 147456.000:   5%|▌         | 409600/8192000 [01:38<19:18, 6716.84it/s]200| main MSE Loss 15488.000 | L1 147456.000:  10%|█         | 819200/8192000 [01:38<14:08, 8687.09it/s]200| main MSE Loss 15488.000 | L1 147456.000:  10%|█         | 819200/8192000 [01:49<14:08, 8687.09it/s]300| main MSE Loss 11648.000 | L1 120320.000:  10%|█         | 819200/8192000 [02:16<14:08, 8687.09it/s]300| main MSE Loss 11648.000 | L1 120320.000:  15%|█▌        | 1228800/8192000 [02:16<12:07, 9573.25it/s]300| main MSE Loss 11648.000 | L1 120320.000:  15%|█▌        | 1228800/8192000 [02:29<12:07, 9573.25it/s]400| main MSE Loss 9792.000 | L1 139264.000:  15%|█▌        | 1228800/8192000 [02:54<12:07, 9573.25it/s] 400| main MSE Loss 9792.000 | L1 139264.000:  20%|██        | 1638400/8192000 [02:54<10:59, 9935.23it/s]400| main MSE Loss 9792.000 | L1 139264.000:  20%|██        | 1638400/8192000 [03:09<10:59, 9935.23it/s]500| main MSE Loss 9216.000 | L1 110080.000:  20%|██        | 1638400/8192000 [03:32<10:59, 9935.23it/s]500| main MSE Loss 9216.000 | L1 110080.000:  25%|██▌       | 2048000/8192000 [03:32<09:57, 10275.85it/s]500| main MSE Loss 9216.000 | L1 110080.000:  25%|██▌       | 2048000/8192000 [03:49<09:57, 10275.85it/s]600| main MSE Loss 9216.000 | L1 115200.000:  25%|██▌       | 2048000/8192000 [04:13<09:57, 10275.85it/s]600| main MSE Loss 9216.000 | L1 115200.000:  30%|███       | 2457600/8192000 [04:13<09:25, 10140.72it/s]600| main MSE Loss 9216.000 | L1 115200.000:  30%|███       | 2457600/8192000 [04:29<09:25, 10140.72it/s]700| main MSE Loss 9728.000 | L1 131072.000:  30%|███       | 2457600/8192000 [05:11<09:25, 10140.72it/s]700| main MSE Loss 9728.000 | L1 131072.000:  35%|███▌      | 2867200/8192000 [05:11<10:00, 8862.54it/s] 700| main MSE Loss 9728.000 | L1 131072.000:  35%|███▌      | 2867200/8192000 [05:22<10:00, 8862.54it/s]800| main MSE Loss 9856.000 | L1 135168.000:  35%|███▌      | 2867200/8192000 [05:54<10:00, 8862.54it/s]800| main MSE Loss 9856.000 | L1 135168.000:  40%|████      | 3276800/8192000 [05:54<09:00, 9099.78it/s]800| main MSE Loss 9856.000 | L1 135168.000:  40%|████      | 3276800/8192000 [06:09<09:00, 9099.78it/s]900| main MSE Loss 9344.000 | L1 109568.000:  40%|████      | 3276800/8192000 [06:47<09:00, 9099.78it/s]900| main MSE Loss 9344.000 | L1 109568.000:  45%|████▌     | 3686400/8192000 [06:47<08:41, 8635.24it/s]900| main MSE Loss 9344.000 | L1 109568.000:  45%|████▌     | 3686400/8192000 [06:59<08:41, 8635.24it/s]1000| main MSE Loss 8576.000 | L1 117760.000:  45%|████▌     | 3686400/8192000 [07:31<08:41, 8635.24it/s]1000| main MSE Loss 8576.000 | L1 117760.000:  50%|█████     | 4096000/8192000 [07:31<07:44, 8818.42it/s]1000| main MSE Loss 8576.000 | L1 117760.000:  50%|█████     | 4096000/8192000 [07:42<07:44, 8818.42it/s]1100| main MSE Loss 9216.000 | L1 112128.000:  50%|█████     | 4096000/8192000 [08:14<07:44, 8818.42it/s]1100| main MSE Loss 9216.000 | L1 112128.000:  55%|█████▌    | 4505600/8192000 [08:14<06:47, 9041.74it/s]1100| main MSE Loss 9216.000 | L1 112128.000:  55%|█████▌    | 4505600/8192000 [08:29<06:47, 9041.74it/s]1200| main MSE Loss 9280.000 | L1 116224.000:  55%|█████▌    | 4505600/8192000 [08:55<06:47, 9041.74it/s]1200| main MSE Loss 9280.000 | L1 116224.000:  60%|██████    | 4915200/8192000 [08:55<05:53, 9279.75it/s]1200| main MSE Loss 9280.000 | L1 116224.000:  60%|██████    | 4915200/8192000 [09:09<05:53, 9279.75it/s]1300| main MSE Loss 9600.000 | L1 112128.000:  60%|██████    | 4915200/8192000 [09:51<05:53, 9279.75it/s]1300| main MSE Loss 9600.000 | L1 112128.000:  65%|██████▌   | 5324800/8192000 [09:51<05:33, 8594.49it/s]1300| main MSE Loss 9600.000 | L1 112128.000:  65%|██████▌   | 5324800/8192000 [10:02<05:33, 8594.49it/s]1400| main MSE Loss 9408.000 | L1 119808.000:  65%|██████▌   | 5324800/8192000 [10:33<05:33, 8594.49it/s]1400| main MSE Loss 9408.000 | L1 119808.000:  70%|███████   | 5734400/8192000 [10:33<04:36, 8877.68it/s]1400| main MSE Loss 9408.000 | L1 119808.000:  70%|███████   | 5734400/8192000 [10:49<04:36, 8877.68it/s]1500| main MSE Loss 8768.000 | L1 117760.000:  70%|███████   | 5734400/8192000 [11:17<04:36, 8877.68it/s]1500| main MSE Loss 8768.000 | L1 117760.000:  75%|███████▌  | 6144000/8192000 [11:17<03:46, 9057.86it/s]1500| main MSE Loss 8768.000 | L1 117760.000:  75%|███████▌  | 6144000/8192000 [11:29<03:46, 9057.86it/s]1600| main MSE Loss 8704.000 | L1 108032.000:  75%|███████▌  | 6144000/8192000 [11:59<03:46, 9057.86it/s]1600| main MSE Loss 8704.000 | L1 108032.000:  80%|████████  | 6553600/8192000 [11:59<02:57, 9216.08it/s]1600| main MSE Loss 8704.000 | L1 108032.000:  80%|████████  | 6553600/8192000 [12:09<02:57, 9216.08it/s]1700| main MSE Loss 9536.000 | L1 136192.000:  80%|████████  | 6553600/8192000 [12:54<02:57, 9216.08it/s]1700| main MSE Loss 9536.000 | L1 136192.000:  85%|████████▌ | 6963200/8192000 [12:54<02:22, 8599.36it/s]1700| main MSE Loss 9536.000 | L1 136192.000:  85%|████████▌ | 6963200/8192000 [13:09<02:22, 8599.36it/s]1800| main MSE Loss 8320.000 | L1 107520.000:  85%|████████▌ | 6963200/8192000 [13:38<02:22, 8599.36it/s]1800| main MSE Loss 8320.000 | L1 107520.000:  90%|█████████ | 7372800/8192000 [13:38<01:32, 8809.28it/s]1800| main MSE Loss 8320.000 | L1 107520.000:  90%|█████████ | 7372800/8192000 [13:50<01:32, 8809.28it/s]1900| main MSE Loss 8320.000 | L1 140288.000:  90%|█████████ | 7372800/8192000 [14:37<01:32, 8809.28it/s]1900| main MSE Loss 8320.000 | L1 140288.000:  95%|█████████▌| 7782400/8192000 [14:37<00:50, 8155.52it/s]1900| main MSE Loss 8320.000 | L1 140288.000:  95%|█████████▌| 7782400/8192000 [14:50<00:50, 8155.52it/s]2000| main MSE Loss 7904.000 | L1 132096.000:  95%|█████████▌| 7782400/8192000 [15:20<00:50, 8155.52it/s]2000| main MSE Loss 7904.000 | L1 132096.000: 100%|██████████| 8192000/8192000 [15:20<00:00, 8500.29it/s]2000| main MSE Loss 7904.000 | L1 132096.000: 100%|██████████| 8192000/8192000 [15:24<00:00, 8863.12it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.361 MB of 657.361 MB uploadedwandb: / 657.381 MB of 657.381 MB uploadedwandb: - 657.381 MB of 657.381 MB uploadedwandb: \ 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▅▅▅▃▂▅▃█▅▆▄▅▆▅▅▄▅▆▆▆▄▆▄▄▅█▅▅▆▆▄▅▆▁▂▅▅▅▅▅
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▃▁▁▁▁▁▄▁▁▁▂▁▁▂▂▂▂▁▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁▅▄▂▁▁
wandb:                    metrics/main_loss ▃▅█▁
wandb:             metrics/main_output_norm ▆▅▇▅▄▆▄█▅▆▄▅▆▅▅▄▅▆▆▅▄▆▄▃▄▇▅▅▆▅▄▅▆▁▂▅▅▅▄▅
wandb:             metrics/main_recons_loss █▅▆▁
wandb:                   metrics/main_score ▁▇██
wandb:           metrics/main_zero_abl_loss ▄▇█▁
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▅▄▅▄▃▅▃█▅▆▄▅▆▅▅▄▅▆▆▆▄▆▄▄▅▇▅▅▆▅▄▅▆▁▂▄▅▅▅▅
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▄▂▁▁█▁▁▁▁▁▂▂▁▁▁▁▁▁▂▁▁▂▃▁▂▁▃▁▁▁▁▂▄▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 15104.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 244.736
wandb:                 losses/main_mse_loss 8384.0
wandb:                  losses/overall_loss 145408.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 10.84766
wandb:                    metrics/main_loss 2.575
wandb:             metrics/main_output_norm 284.0
wandb:             metrics/main_recons_loss 2.79531
wandb:                   metrics/main_score 0.71602
wandb:           metrics/main_zero_abl_loss 3.35
wandb:  metrics/mean_log10_feature_sparsity -2.55578
wandb:           metrics/target_output_norm 282.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 0.42567
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_college_math_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_math/runs/yz8a8xkm
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-college_math
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_070605-yz8a8xkm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.43M/689M [00:00<01:03, 10.8MB/s]sae_weights.safetensors:   0%|          | 2.52M/689M [00:00<02:12, 5.19MB/s]sae_weights.safetensors:   1%|          | 3.48M/689M [00:00<01:53, 6.02MB/s]sae_weights.safetensors:   1%|          | 5.28M/689M [00:00<01:15, 9.01MB/s]sae_weights.safetensors:   2%|▏         | 11.1M/689M [00:00<00:32, 20.9MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<00:47, 14.3MB/s]sae_weights.safetensors:   3%|▎         | 19.9M/689M [00:01<00:36, 18.3MB/s]sae_weights.safetensors:   3%|▎         | 22.5M/689M [00:01<00:41, 16.0MB/s]sae_weights.safetensors:   4%|▎         | 24.6M/689M [00:01<00:48, 13.8MB/s]sae_weights.safetensors:   4%|▍         | 26.4M/689M [00:01<00:45, 14.4MB/s]sae_weights.safetensors:   4%|▍         | 30.8M/689M [00:02<00:32, 20.1MB/s]sae_weights.safetensors:   5%|▍         | 33.3M/689M [00:02<00:48, 13.6MB/s]sae_weights.safetensors:   5%|▌         | 36.2M/689M [00:02<00:47, 13.6MB/s]sae_weights.safetensors:   6%|▌         | 38.0M/689M [00:02<00:53, 12.3MB/s]sae_weights.safetensors:   6%|▌         | 39.9M/689M [00:02<00:50, 12.9MB/s]sae_weights.safetensors:   6%|▌         | 42.3M/689M [00:03<00:43, 14.8MB/s]sae_weights.safetensors:   7%|▋         | 45.4M/689M [00:03<00:36, 17.9MB/s]sae_weights.safetensors:   7%|▋         | 48.0M/689M [00:03<01:03, 10.0MB/s]sae_weights.safetensors:   7%|▋         | 51.3M/689M [00:03<00:49, 12.8MB/s]sae_weights.safetensors:   8%|▊         | 53.2M/689M [00:04<00:58, 10.9MB/s]sae_weights.safetensors:   8%|▊         | 54.8M/689M [00:04<00:57, 11.1MB/s]sae_weights.safetensors:   9%|▊         | 58.6M/689M [00:04<00:41, 15.3MB/s]sae_weights.safetensors:   9%|▉         | 62.9M/689M [00:04<00:30, 20.5MB/s]sae_weights.safetensors:  10%|▉         | 65.5M/689M [00:04<00:52, 11.8MB/s]sae_weights.safetensors:  10%|▉         | 67.5M/689M [00:05<00:49, 12.5MB/s]sae_weights.safetensors:  10%|█         | 69.3M/689M [00:05<00:52, 11.9MB/s]sae_weights.safetensors:  10%|█         | 71.9M/689M [00:05<00:45, 13.4MB/s]sae_weights.safetensors:  11%|█         | 75.9M/689M [00:05<00:33, 18.4MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:05<00:45, 13.3MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:06<00:36, 16.4MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:07<00:23, 24.7MB/s] sae_weights.safetensors:  17%|█▋        | 116M/689M [00:07<00:22, 25.3MB/s]sae_weights.safetensors:  17%|█▋        | 119M/689M [00:07<00:25, 22.5MB/s]sae_weights.safetensors:  18%|█▊        | 121M/689M [00:07<00:28, 20.1MB/s]sae_weights.safetensors:  18%|█▊        | 123M/689M [00:07<00:28, 20.1MB/s]sae_weights.safetensors:  19%|█▊        | 128M/689M [00:07<00:23, 23.4MB/s]sae_weights.safetensors:  19%|█▉        | 130M/689M [00:08<00:35, 15.7MB/s]sae_weights.safetensors:  19%|█▉        | 132M/689M [00:08<00:35, 15.8MB/s]sae_weights.safetensors:  19%|█▉        | 134M/689M [00:08<00:35, 15.8MB/s]sae_weights.safetensors:  20%|█▉        | 136M/689M [00:08<00:42, 12.9MB/s]sae_weights.safetensors:  20%|█▉        | 138M/689M [00:08<00:40, 13.6MB/s]sae_weights.safetensors:  20%|██        | 141M/689M [00:08<00:32, 16.8MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:09<00:51, 10.6MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:09<00:26, 20.0MB/s]sae_weights.safetensors:  24%|██▍       | 165M/689M [00:10<00:23, 22.4MB/s]sae_weights.safetensors:  24%|██▍       | 167M/689M [00:10<00:24, 21.7MB/s]sae_weights.safetensors:  25%|██▍       | 170M/689M [00:10<00:31, 16.4MB/s]sae_weights.safetensors:  25%|██▌       | 173M/689M [00:10<00:27, 19.0MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:11<00:38, 13.3MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:11<00:19, 25.7MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:11<00:15, 30.3MB/s]sae_weights.safetensors:  31%|███       | 213M/689M [00:11<00:15, 30.6MB/s]sae_weights.safetensors:  31%|███▏      | 216M/689M [00:12<00:20, 23.1MB/s]sae_weights.safetensors:  32%|███▏      | 218M/689M [00:12<00:20, 22.9MB/s]sae_weights.safetensors:  32%|███▏      | 221M/689M [00:12<00:19, 23.5MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:13<00:34, 13.7MB/s]sae_weights.safetensors:  33%|███▎      | 228M/689M [00:13<00:27, 16.5MB/s]sae_weights.safetensors:  34%|███▎      | 231M/689M [00:13<00:31, 14.5MB/s]sae_weights.safetensors:  34%|███▍      | 233M/689M [00:13<00:31, 14.6MB/s]sae_weights.safetensors:  34%|███▍      | 235M/689M [00:13<00:29, 15.5MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:13<00:21, 21.1MB/s]sae_weights.safetensors:  35%|███▌      | 242M/689M [00:14<00:32, 13.9MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:14<00:17, 25.2MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:14<00:12, 32.3MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:15<00:10, 37.8MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:15<00:10, 37.8MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:15<00:09, 39.5MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:16<00:08, 42.6MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:16<00:07, 42.3MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:16<00:07, 43.9MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:17<00:06, 46.5MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:17<00:06, 47.7MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:17<00:06, 45.4MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:18<00:06, 42.0MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:19<00:06, 36.4MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:19<00:05, 39.2MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:19<00:05, 38.1MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:20<00:04, 40.6MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:20<00:04, 41.8MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:20<00:03, 42.2MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:21<00:03, 41.0MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:21<00:03, 41.3MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:22<00:02, 42.6MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:22<00:02, 44.0MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:22<00:01, 41.1MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:23<00:01, 38.1MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:23<00:01, 39.9MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:24<00:00, 40.8MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:24<00:00, 34.8MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:24<00:00, 37.8MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:25<00:00, 27.4MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.20s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_072400-dy6h46yg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_econ_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-econ
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-econ/runs/dy6h46yg
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 169.3899383544922
New distances: 130.3545684814453
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 19200.000 | L1 100864.000:   0%|          | 0/8192000 [01:11<?, ?it/s]100| main MSE Loss 19200.000 | L1 100864.000:   5%|▌         | 409600/8192000 [01:11<22:42, 5712.31it/s]100| main MSE Loss 19200.000 | L1 100864.000:   5%|▌         | 409600/8192000 [01:27<22:42, 5712.31it/s]200| main MSE Loss 15616.000 | L1 95744.000:   5%|▌         | 409600/8192000 [01:56<22:42, 5712.31it/s] 200| main MSE Loss 15616.000 | L1 95744.000:  10%|█         | 819200/8192000 [01:56<16:47, 7314.93it/s]200| main MSE Loss 15616.000 | L1 95744.000:  10%|█         | 819200/8192000 [02:07<16:47, 7314.93it/s]300| main MSE Loss 13632.000 | L1 116224.000:  10%|█         | 819200/8192000 [02:42<16:47, 7314.93it/s]300| main MSE Loss 13632.000 | L1 116224.000:  15%|█▌        | 1228800/8192000 [02:42<14:30, 8003.10it/s]300| main MSE Loss 13632.000 | L1 116224.000:  15%|█▌        | 1228800/8192000 [02:57<14:30, 8003.10it/s]400| main MSE Loss 10176.000 | L1 128000.000:  15%|█▌        | 1228800/8192000 [03:27<14:30, 8003.10it/s]400| main MSE Loss 10176.000 | L1 128000.000:  20%|██        | 1638400/8192000 [03:27<12:59, 8407.05it/s]400| main MSE Loss 10176.000 | L1 128000.000:  20%|██        | 1638400/8192000 [03:37<12:59, 8407.05it/s]500| main MSE Loss 8256.000 | L1 117248.000:  20%|██        | 1638400/8192000 [04:11<12:59, 8407.05it/s] 500| main MSE Loss 8256.000 | L1 117248.000:  25%|██▌       | 2048000/8192000 [04:11<11:47, 8678.22it/s]500| main MSE Loss 8256.000 | L1 117248.000:  25%|██▌       | 2048000/8192000 [04:27<11:47, 8678.22it/s]600| main MSE Loss 9216.000 | L1 126464.000:  25%|██▌       | 2048000/8192000 [04:57<11:47, 8678.22it/s]600| main MSE Loss 9216.000 | L1 126464.000:  30%|███       | 2457600/8192000 [04:57<10:52, 8790.91it/s]600| main MSE Loss 9216.000 | L1 126464.000:  30%|███       | 2457600/8192000 [05:07<10:52, 8790.91it/s]700| main MSE Loss 8320.000 | L1 107520.000:  30%|███       | 2457600/8192000 [05:52<10:52, 8790.91it/s]700| main MSE Loss 8320.000 | L1 107520.000:  35%|███▌      | 2867200/8192000 [05:52<10:44, 8257.03it/s]700| main MSE Loss 8320.000 | L1 107520.000:  35%|███▌      | 2867200/8192000 [06:07<10:44, 8257.03it/s]800| main MSE Loss 8768.000 | L1 117248.000:  35%|███▌      | 2867200/8192000 [06:39<10:44, 8257.03it/s]800| main MSE Loss 8768.000 | L1 117248.000:  40%|████      | 3276800/8192000 [06:39<09:43, 8421.04it/s]800| main MSE Loss 8768.000 | L1 117248.000:  40%|████      | 3276800/8192000 [06:49<09:43, 8421.04it/s]900| main MSE Loss 8576.000 | L1 122880.000:  40%|████      | 3276800/8192000 [07:36<09:43, 8421.04it/s]900| main MSE Loss 8576.000 | L1 122880.000:  45%|████▌     | 3686400/8192000 [07:36<09:24, 7976.12it/s]900| main MSE Loss 8576.000 | L1 122880.000:  45%|████▌     | 3686400/8192000 [07:47<09:24, 7976.12it/s]1000| main MSE Loss 9280.000 | L1 112640.000:  45%|████▌     | 3686400/8192000 [08:17<09:24, 7976.12it/s]1000| main MSE Loss 9280.000 | L1 112640.000:  50%|█████     | 4096000/8192000 [08:17<08:02, 8490.45it/s]1000| main MSE Loss 9280.000 | L1 112640.000:  50%|█████     | 4096000/8192000 [08:29<08:02, 8490.45it/s]1100| main MSE Loss 8384.000 | L1 88576.000:  50%|█████     | 4096000/8192000 [09:06<08:02, 8490.45it/s] 1100| main MSE Loss 8384.000 | L1 88576.000:  55%|█████▌    | 4505600/8192000 [09:06<07:14, 8487.18it/s]1100| main MSE Loss 8384.000 | L1 88576.000:  55%|█████▌    | 4505600/8192000 [09:17<07:14, 8487.18it/s]1200| main MSE Loss 7872.000 | L1 136192.000:  55%|█████▌    | 4505600/8192000 [09:52<07:14, 8487.18it/s]1200| main MSE Loss 7872.000 | L1 136192.000:  60%|██████    | 4915200/8192000 [09:52<06:21, 8594.34it/s]1200| main MSE Loss 7872.000 | L1 136192.000:  60%|██████    | 4915200/8192000 [10:07<06:21, 8594.34it/s]1300| main MSE Loss 7744.000 | L1 151552.000:  60%|██████    | 4915200/8192000 [10:49<06:21, 8594.34it/s]1300| main MSE Loss 7744.000 | L1 151552.000:  65%|██████▌   | 5324800/8192000 [10:49<05:53, 8105.82it/s]1300| main MSE Loss 7744.000 | L1 151552.000:  65%|██████▌   | 5324800/8192000 [11:00<05:53, 8105.82it/s]1400| main MSE Loss 7552.000 | L1 125440.000:  65%|██████▌   | 5324800/8192000 [11:33<05:53, 8105.82it/s]1400| main MSE Loss 7552.000 | L1 125440.000:  70%|███████   | 5734400/8192000 [11:33<04:51, 8443.57it/s]1400| main MSE Loss 7552.000 | L1 125440.000:  70%|███████   | 5734400/8192000 [11:47<04:51, 8443.57it/s]1500| main MSE Loss 7584.000 | L1 129024.000:  70%|███████   | 5734400/8192000 [12:19<04:51, 8443.57it/s]1500| main MSE Loss 7584.000 | L1 129024.000:  75%|███████▌  | 6144000/8192000 [12:19<03:57, 8607.32it/s]1500| main MSE Loss 7584.000 | L1 129024.000:  75%|███████▌  | 6144000/8192000 [12:30<03:57, 8607.32it/s]1600| main MSE Loss 7520.000 | L1 126464.000:  75%|███████▌  | 6144000/8192000 [13:03<03:57, 8607.32it/s]1600| main MSE Loss 7520.000 | L1 126464.000:  80%|████████  | 6553600/8192000 [13:03<03:06, 8796.36it/s]1600| main MSE Loss 7520.000 | L1 126464.000:  80%|████████  | 6553600/8192000 [13:17<03:06, 8796.36it/s]1700| main MSE Loss 7360.000 | L1 135168.000:  80%|████████  | 6553600/8192000 [13:58<03:06, 8796.36it/s]1700| main MSE Loss 7360.000 | L1 135168.000:  85%|████████▌ | 6963200/8192000 [13:58<02:27, 8352.22it/s]1700| main MSE Loss 7360.000 | L1 135168.000:  85%|████████▌ | 6963200/8192000 [14:10<02:27, 8352.22it/s]1800| main MSE Loss 7712.000 | L1 136192.000:  85%|████████▌ | 6963200/8192000 [14:42<02:27, 8352.22it/s]1800| main MSE Loss 7712.000 | L1 136192.000:  90%|█████████ | 7372800/8192000 [14:42<01:35, 8572.74it/s]1800| main MSE Loss 7712.000 | L1 136192.000:  90%|█████████ | 7372800/8192000 [14:57<01:35, 8572.74it/s]1900| main MSE Loss 7296.000 | L1 161792.000:  90%|█████████ | 7372800/8192000 [15:40<01:35, 8572.74it/s]1900| main MSE Loss 7296.000 | L1 161792.000:  95%|█████████▌| 7782400/8192000 [15:40<00:50, 8078.12it/s]1900| main MSE Loss 7296.000 | L1 161792.000:  95%|█████████▌| 7782400/8192000 [15:57<00:50, 8078.12it/s]2000| main MSE Loss 7360.000 | L1 79360.000:  95%|█████████▌| 7782400/8192000 [16:24<00:50, 8078.12it/s] 2000| main MSE Loss 7360.000 | L1 79360.000: 100%|██████████| 8192000/8192000 [16:24<00:00, 8429.51it/s]2000| main MSE Loss 7360.000 | L1 79360.000: 100%|██████████| 8192000/8192000 [16:27<00:00, 8295.87it/s]
wandb: - 657.361 MB of 657.361 MB uploadedwandb: \ 657.361 MB of 657.361 MB uploadedwandb: | 657.361 MB of 657.361 MB uploadedwandb: / 657.381 MB of 657.381 MB uploadedwandb: - 657.381 MB of 657.381 MB uploadedwandb: \ 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▇▄▂▆▄▅▂▄▄█▃▂▁▁▃▃▁▂▃▂▅▆▇▂▆▆▂▂▃▁▂▁▇▃▃▂▄▅▃▆
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 █▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    metrics/main_loss █▄▇▁
wandb:             metrics/main_output_norm ▆▅▅█▆▆▃▄▄▇▃▂▁▁▃▃▁▂▃▂▄▆▆▂▆▅▂▂▃▁▂▁▆▃▃▂▄▄▃▅
wandb:             metrics/main_recons_loss █▂▂▁
wandb:                   metrics/main_score ▁███
wandb:           metrics/main_zero_abl_loss █▄▆▁
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▅▂▃▆▄▅▂▄▄█▃▂▁▁▃▃▂▂▃▂▅▆▇▂▆▅▂▂▃▁▂▁▇▄▃▂▄▅▄▆
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▂▅█▄▂▂▃▃▃▃▄▅
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 14720.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 294.912
wandb:                 losses/main_mse_loss 7328.0
wandb:                  losses/overall_loss 168960.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 11.94751
wandb:                    metrics/main_loss 2.2
wandb:             metrics/main_output_norm 326.0
wandb:             metrics/main_recons_loss 2.38437
wandb:                   metrics/main_score 0.70625
wandb:           metrics/main_zero_abl_loss 2.82656
wandb:  metrics/mean_log10_feature_sparsity -3.14137
wandb:           metrics/target_output_norm 332.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 17.76226
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_econ_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-econ/runs/dy6h46yg
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-econ
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_072400-dy6h46yg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Reached end of dataset. Resetting iterator.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 524k/689M [00:00<03:25, 3.36MB/s]sae_weights.safetensors:   0%|          | 860k/689M [00:00<05:01, 2.28MB/s]sae_weights.safetensors:   1%|          | 3.92M/689M [00:00<01:04, 10.7MB/s]sae_weights.safetensors:   1%|          | 5.39M/689M [00:00<01:05, 10.5MB/s]sae_weights.safetensors:   1%|          | 6.60M/689M [00:00<01:07, 10.1MB/s]sae_weights.safetensors:   1%|          | 7.72M/689M [00:00<01:09, 9.76MB/s]sae_weights.safetensors:   1%|▏         | 9.68M/689M [00:00<00:56, 12.0MB/s]sae_weights.safetensors:   2%|▏         | 13.5M/689M [00:01<00:36, 18.6MB/s]sae_weights.safetensors:   2%|▏         | 16.0M/689M [00:01<01:07, 10.0MB/s]sae_weights.safetensors:   3%|▎         | 18.3M/689M [00:01<00:57, 11.6MB/s]sae_weights.safetensors:   3%|▎         | 19.9M/689M [00:01<01:03, 10.5MB/s]sae_weights.safetensors:   3%|▎         | 21.3M/689M [00:02<01:17, 8.58MB/s]sae_weights.safetensors:   3%|▎         | 22.4M/689M [00:02<01:24, 7.87MB/s]sae_weights.safetensors:   3%|▎         | 23.6M/689M [00:02<01:21, 8.16MB/s]sae_weights.safetensors:   4%|▍         | 25.9M/689M [00:02<01:01, 10.8MB/s]sae_weights.safetensors:   4%|▍         | 29.6M/689M [00:02<00:40, 16.2MB/s]sae_weights.safetensors:   5%|▍         | 32.0M/689M [00:03<01:12, 9.01MB/s]sae_weights.safetensors:   7%|▋         | 48.0M/689M [00:03<00:30, 21.1MB/s]sae_weights.safetensors:   8%|▊         | 52.6M/689M [00:03<00:28, 22.1MB/s]sae_weights.safetensors:   8%|▊         | 54.9M/689M [00:04<00:33, 19.0MB/s]sae_weights.safetensors:   8%|▊         | 57.3M/689M [00:04<00:33, 19.0MB/s]sae_weights.safetensors:   9%|▉         | 60.8M/689M [00:04<00:29, 21.4MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:05<01:08, 9.19MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:05<00:35, 17.3MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:07<00:46, 12.7MB/s]sae_weights.safetensors:  14%|█▍        | 98.6M/689M [00:07<00:45, 12.9MB/s]sae_weights.safetensors:  15%|█▍        | 100M/689M [00:07<00:46, 12.7MB/s] sae_weights.safetensors:  15%|█▍        | 102M/689M [00:07<00:44, 13.1MB/s]sae_weights.safetensors:  15%|█▌        | 104M/689M [00:07<00:47, 12.3MB/s]sae_weights.safetensors:  15%|█▌        | 106M/689M [00:08<00:50, 11.6MB/s]sae_weights.safetensors:  16%|█▌        | 108M/689M [00:08<00:46, 12.5MB/s]sae_weights.safetensors:  16%|█▌        | 111M/689M [00:08<00:38, 15.2MB/s]sae_weights.safetensors:  16%|█▋        | 113M/689M [00:08<01:04, 8.94MB/s]sae_weights.safetensors:  19%|█▊        | 128M/689M [00:09<00:28, 19.8MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:09<00:19, 27.5MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:10<00:16, 32.1MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:10<00:14, 34.7MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:10<00:13, 37.7MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:11<00:12, 39.7MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:11<00:11, 39.4MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:11<00:11, 40.4MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:12<00:10, 42.9MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:12<00:10, 39.7MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:13<00:09, 43.4MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:13<00:08, 45.3MB/s]sae_weights.safetensors:  45%|████▌     | 310M/689M [00:13<00:08, 45.3MB/s]sae_weights.safetensors:  46%|████▌     | 315M/689M [00:13<00:11, 33.1MB/s]sae_weights.safetensors:  46%|████▌     | 318M/689M [00:13<00:11, 32.6MB/s]sae_weights.safetensors:  47%|████▋     | 322M/689M [00:14<00:18, 20.1MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:15<00:16, 21.5MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:15<00:12, 27.6MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:15<00:09, 33.4MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:16<00:08, 34.4MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:16<00:07, 37.8MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:17<00:07, 35.1MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:17<00:06, 38.0MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:17<00:06, 39.8MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:18<00:04, 45.1MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:18<00:04, 42.6MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:18<00:04, 42.7MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:19<00:03, 45.0MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:19<00:03, 45.0MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:19<00:03, 43.3MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:20<00:02, 46.2MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:20<00:02, 48.0MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:20<00:02, 44.1MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:21<00:01, 44.9MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:21<00:01, 45.7MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:21<00:01, 46.4MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:22<00:00, 44.4MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:22<00:00, 42.2MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:23<00:00, 45.1MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:23<00:00, 29.6MB/s]
Files uploaded successfully.
Run name: 9216-L1-500-LR-0.001-Tokens-8.192e+06
n_tokens_per_buffer (millions): 0.262144
Lower bound: n_contexts_per_buffer (millions): 0.002048
Total training steps: 2000
Total wandb updates: 66
n_tokens_per_feature_sampling_window (millions): 524.288
n_tokens_per_dead_feature_window (millions): 524.288
We will reset the sparsity calculation 2 times.
Number tokens in sparsity calculation window: 4.10e+06
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.20s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.70s/it]
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /root/specialised-SAEs/sae_lens/jacob/wandb/run-20240810_074250-z6dchc0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b_layer13_history_l1=500_expansion=4_tokens=8192000_gsaewidth=65k
wandb: ⭐️ View project at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-history
wandb: 🚀 View run at https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-history/runs/z6dchc0r
Loaded pretrained model gemma-2-2b into HookedTransformer

model loaded
model.cfg.dtype =  torch.bfloat16
model.W_E.dtype =  torch.bfloat16

no control dataset!
Warning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.
load state dict dtype bfloat16
loaded sae from state dict, dtype torch.bfloat16

self.cfg.dtype bfloat16
gsae loaded, dtype torch.bfloat16

Reinitializing b_dec with mean of activations
Previous distances: 169.5294952392578
New distances: 127.63044738769531
Training SAE:   0%|          | 0/8192000 [00:00<?, ?it/s]100| main MSE Loss 77312.000 | L1 167936.000:   0%|          | 0/8192000 [01:05<?, ?it/s]100| main MSE Loss 77312.000 | L1 167936.000:   5%|▌         | 409600/8192000 [01:05<20:43, 6259.91it/s]100| main MSE Loss 77312.000 | L1 167936.000:   5%|▌         | 409600/8192000 [01:17<20:43, 6259.91it/s]200| main MSE Loss 15552.000 | L1 113664.000:   5%|▌         | 409600/8192000 [01:45<20:43, 6259.91it/s]200| main MSE Loss 15552.000 | L1 113664.000:  10%|█         | 819200/8192000 [01:45<15:12, 8079.20it/s]200| main MSE Loss 15552.000 | L1 113664.000:  10%|█         | 819200/8192000 [01:57<15:12, 8079.20it/s]300| main MSE Loss 12032.000 | L1 95232.000:  10%|█         | 819200/8192000 [02:28<15:12, 8079.20it/s] 300| main MSE Loss 12032.000 | L1 95232.000:  15%|█▌        | 1228800/8192000 [02:28<13:16, 8744.69it/s]300| main MSE Loss 12032.000 | L1 95232.000:  15%|█▌        | 1228800/8192000 [02:40<13:16, 8744.69it/s]400| main MSE Loss 9152.000 | L1 139264.000:  15%|█▌        | 1228800/8192000 [03:10<13:16, 8744.69it/s]400| main MSE Loss 9152.000 | L1 139264.000:  20%|██        | 1638400/8192000 [03:10<11:59, 9110.17it/s]400| main MSE Loss 9152.000 | L1 139264.000:  20%|██        | 1638400/8192000 [03:20<11:59, 9110.17it/s]500| main MSE Loss 7712.000 | L1 129024.000:  20%|██        | 1638400/8192000 [03:51<11:59, 9110.17it/s]500| main MSE Loss 7712.000 | L1 129024.000:  25%|██▌       | 2048000/8192000 [03:51<10:52, 9416.91it/s]500| main MSE Loss 7712.000 | L1 129024.000:  25%|██▌       | 2048000/8192000 [04:08<10:52, 9416.91it/s]600| main MSE Loss 8256.000 | L1 131072.000:  25%|██▌       | 2048000/8192000 [04:33<10:52, 9416.91it/s]600| main MSE Loss 8256.000 | L1 131072.000:  30%|███       | 2457600/8192000 [04:33<10:04, 9483.18it/s]600| main MSE Loss 8256.000 | L1 131072.000:  30%|███       | 2457600/8192000 [04:48<10:04, 9483.18it/s]700| main MSE Loss 7296.000 | L1 129024.000:  30%|███       | 2457600/8192000 [05:30<10:04, 9483.18it/s]700| main MSE Loss 7296.000 | L1 129024.000:  35%|███▌      | 2867200/8192000 [05:30<10:18, 8607.32it/s]700| main MSE Loss 7296.000 | L1 129024.000:  35%|███▌      | 2867200/8192000 [05:40<10:18, 8607.32it/s]800| main MSE Loss 7424.000 | L1 138240.000:  35%|███▌      | 2867200/8192000 [06:13<10:18, 8607.32it/s]800| main MSE Loss 7424.000 | L1 138240.000:  40%|████      | 3276800/8192000 [06:13<09:14, 8865.29it/s]800| main MSE Loss 7424.000 | L1 138240.000:  40%|████      | 3276800/8192000 [06:28<09:14, 8865.29it/s]900| main MSE Loss 8032.000 | L1 132096.000:  40%|████      | 3276800/8192000 [07:08<09:14, 8865.29it/s]900| main MSE Loss 8032.000 | L1 132096.000:  45%|████▌     | 3686400/8192000 [07:08<08:57, 8382.35it/s]900| main MSE Loss 8032.000 | L1 132096.000:  45%|████▌     | 3686400/8192000 [07:18<08:57, 8382.35it/s]1000| main MSE Loss 7232.000 | L1 119808.000:  45%|████▌     | 3686400/8192000 [07:52<08:57, 8382.35it/s]1000| main MSE Loss 7232.000 | L1 119808.000:  50%|█████     | 4096000/8192000 [07:52<07:55, 8615.18it/s]1000| main MSE Loss 7232.000 | L1 119808.000:  50%|█████     | 4096000/8192000 [08:08<07:55, 8615.18it/s]1100| main MSE Loss 7424.000 | L1 87040.000:  50%|█████     | 4096000/8192000 [08:35<07:55, 8615.18it/s] 1100| main MSE Loss 7424.000 | L1 87040.000:  55%|█████▌    | 4505600/8192000 [08:35<06:53, 8910.38it/s]1100| main MSE Loss 7424.000 | L1 87040.000:  55%|█████▌    | 4505600/8192000 [08:48<06:53, 8910.38it/s]1200| main MSE Loss 7904.000 | L1 128000.000:  55%|█████▌    | 4505600/8192000 [09:20<06:53, 8910.38it/s]1200| main MSE Loss 7904.000 | L1 128000.000:  60%|██████    | 4915200/8192000 [09:20<06:05, 8960.76it/s]1200| main MSE Loss 7904.000 | L1 128000.000:  60%|██████    | 4915200/8192000 [09:30<06:05, 8960.76it/s]1300| main MSE Loss 7136.000 | L1 155648.000:  60%|██████    | 4915200/8192000 [10:16<06:05, 8960.76it/s]1300| main MSE Loss 7136.000 | L1 155648.000:  65%|██████▌   | 5324800/8192000 [10:16<05:41, 8391.76it/s]1300| main MSE Loss 7136.000 | L1 155648.000:  65%|██████▌   | 5324800/8192000 [10:28<05:41, 8391.76it/s]1400| main MSE Loss 8384.000 | L1 79872.000:  65%|██████▌   | 5324800/8192000 [10:57<05:41, 8391.76it/s] 1400| main MSE Loss 8384.000 | L1 79872.000:  70%|███████   | 5734400/8192000 [10:57<04:39, 8802.84it/s]1400| main MSE Loss 8384.000 | L1 79872.000:  70%|███████   | 5734400/8192000 [11:08<04:39, 8802.84it/s]1500| main MSE Loss 7584.000 | L1 134144.000:  70%|███████   | 5734400/8192000 [11:39<04:39, 8802.84it/s]1500| main MSE Loss 7584.000 | L1 134144.000:  75%|███████▌  | 6144000/8192000 [11:39<03:45, 9065.53it/s]1500| main MSE Loss 7584.000 | L1 134144.000:  75%|███████▌  | 6144000/8192000 [11:50<03:45, 9065.53it/s]1600| main MSE Loss 7200.000 | L1 114688.000:  75%|███████▌  | 6144000/8192000 [12:22<03:45, 9065.53it/s]1600| main MSE Loss 7200.000 | L1 114688.000:  80%|████████  | 6553600/8192000 [12:22<02:57, 9231.87it/s]1600| main MSE Loss 7200.000 | L1 114688.000:  80%|████████  | 6553600/8192000 [12:38<02:57, 9231.87it/s]1700| main MSE Loss 7008.000 | L1 120832.000:  80%|████████  | 6553600/8192000 [13:17<02:57, 9231.87it/s]1700| main MSE Loss 7008.000 | L1 120832.000:  85%|████████▌ | 6963200/8192000 [13:17<02:22, 8600.51it/s]1700| main MSE Loss 7008.000 | L1 120832.000:  85%|████████▌ | 6963200/8192000 [13:28<02:22, 8600.51it/s]1800| main MSE Loss 6848.000 | L1 135168.000:  85%|████████▌ | 6963200/8192000 [14:00<02:22, 8600.51it/s]1800| main MSE Loss 6848.000 | L1 135168.000:  90%|█████████ | 7372800/8192000 [14:00<01:32, 8821.22it/s]1800| main MSE Loss 6848.000 | L1 135168.000:  90%|█████████ | 7372800/8192000 [14:10<01:32, 8821.22it/s]1900| main MSE Loss 6688.000 | L1 78848.000:  90%|█████████ | 7372800/8192000 [15:01<01:32, 8821.22it/s] 1900| main MSE Loss 6688.000 | L1 78848.000:  95%|█████████▌| 7782400/8192000 [15:01<00:50, 8101.18it/s]1900| main MSE Loss 6688.000 | L1 78848.000:  95%|█████████▌| 7782400/8192000 [15:19<00:50, 8101.18it/s]2000| main MSE Loss 7008.000 | L1 83456.000:  95%|█████████▌| 7782400/8192000 [15:45<00:50, 8101.18it/s]2000| main MSE Loss 7008.000 | L1 83456.000: 100%|██████████| 8192000/8192000 [15:45<00:00, 8389.85it/s]2000| main MSE Loss 7008.000 | L1 83456.000: 100%|██████████| 8192000/8192000 [15:49<00:00, 8629.61it/s]
wandb: - 657.381 MB of 657.390 MB uploadedwandb: \ 657.381 MB of 657.390 MB uploadedwandb: | 657.397 MB of 657.397 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       details/current_l1_coefficient ▁▄██████████████████████████████████████
wandb:        details/current_learning_rate █████████████████████████████████▇▆▅▄▃▂▁
wandb:            details/n_training_tokens ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: losses/auxiliary_reconstruction_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:               losses/ghost_grad_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                       losses/l1_loss ▂▆▁▃▅▄▄▄▆▃▅▂█▄▆▆▁▂▅▄▄▆▅▅▄▃▄▅▄▃▅▅▄▃▄▂▄▃▄▅
wandb:                 losses/main_mse_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  losses/overall_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 metrics/control_loss ▁▁▁▁
wandb:          metrics/control_recons_loss ▁▁▁▁
wandb:                metrics/control_score ▁▁▁▁
wandb:        metrics/control_zero_abl_loss ▁▁▁▁
wandb:                           metrics/l0 ▂▂▃▃▄▃▂▃▃▄▄▄▇▃▃▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▂▅▅▄▃▃▅▃█
wandb:                    metrics/main_loss ▅▅█▁
wandb:             metrics/main_output_norm ▅▆▄▅▇▆▄▅▆▂▄▂█▄▆▅▁▁▅▄▄▅▄▅▄▃▄▅▄▃▅▅▄▃▃▂▄▂▄▅
wandb:             metrics/main_recons_loss █▃▅▁
wandb:                   metrics/main_score ▁███
wandb:           metrics/main_zero_abl_loss ▆▅█▁
wandb:  metrics/mean_log10_feature_sparsity █▁
wandb:           metrics/target_output_norm ▃▅▁▃▅▄▃▄▅▂▄▂█▄▆▅▁▁▅▄▄▅▄▅▄▃▄▅▄▃▅▅▄▃▃▂▄▂▄▅
wandb:                  sparsity/below_1e-5 ▁▁
wandb:                  sparsity/below_1e-6 ▁▁
wandb:               sparsity/dead_features ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     sparsity/mean_passes_since_fired ▄▂▁▁▁▁▃▁▁▁▁▁▁▁▁▂▁▁▁▄▁▂▁▁▁▂█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:       details/current_l1_coefficient 500
wandb:        details/current_learning_rate 5e-05
wandb:            details/n_training_tokens 8110080
wandb: losses/auxiliary_reconstruction_loss 15424.0
wandb:              losses/control_mse_loss nan
wandb:               losses/ghost_grad_loss 0.0
wandb:                       losses/l1_loss 270.336
wandb:                 losses/main_mse_loss 7584.0
wandb:                  losses/overall_loss 157696.0
wandb:                 metrics/control_loss 0.0
wandb:          metrics/control_output_norm nan
wandb:          metrics/control_recons_loss 0.0
wandb:                metrics/control_score 0.0
wandb:        metrics/control_zero_abl_loss 0.0
wandb:                           metrics/l0 229.01343
wandb:                    metrics/main_loss 2.56719
wandb:             metrics/main_output_norm 302.0
wandb:             metrics/main_recons_loss 2.73281
wandb:                   metrics/main_score 0.74609
wandb:           metrics/main_zero_abl_loss 3.21875
wandb:  metrics/mean_log10_feature_sparsity -2.13929
wandb:           metrics/target_output_norm 304.0
wandb:                  sparsity/below_1e-5 0
wandb:                  sparsity/below_1e-6 0
wandb:               sparsity/dead_features 0
wandb:     sparsity/mean_passes_since_fired 0.0
wandb: 
wandb: 🚀 View run gemma-2-2b_layer13_history_l1=500_expansion=4_tokens=8192000_gsaewidth=65k at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-history/runs/z6dchc0r
wandb: ⭐️ View project at: https://wandb.ai/jacobcd52/gemma-2-2b-layer13-ssae-history
wandb: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240810_074250-z6dchc0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
sae_weights.safetensors:   0%|          | 0.00/689M [00:00<?, ?B/s]sae_weights.safetensors:   0%|          | 1.86M/689M [00:00<00:49, 14.0MB/s]sae_weights.safetensors:   0%|          | 3.26M/689M [00:00<01:46, 6.45MB/s]sae_weights.safetensors:   1%|          | 5.00M/689M [00:00<01:17, 8.78MB/s]sae_weights.safetensors:   1%|          | 8.27M/689M [00:00<00:46, 14.8MB/s]sae_weights.safetensors:   2%|▏         | 13.7M/689M [00:00<00:27, 24.8MB/s]sae_weights.safetensors:   2%|▏         | 16.7M/689M [00:01<00:46, 14.5MB/s]sae_weights.safetensors:   5%|▍         | 32.0M/689M [00:01<00:28, 23.2MB/s]sae_weights.safetensors:   5%|▌         | 35.3M/689M [00:01<00:27, 23.6MB/s]sae_weights.safetensors:   5%|▌         | 37.9M/689M [00:02<00:31, 20.7MB/s]sae_weights.safetensors:   6%|▌         | 40.1M/689M [00:02<00:51, 12.6MB/s]sae_weights.safetensors:   6%|▌         | 41.7M/689M [00:02<00:52, 12.2MB/s]sae_weights.safetensors:   7%|▋         | 46.7M/689M [00:02<00:37, 17.0MB/s]sae_weights.safetensors:   7%|▋         | 49.0M/689M [00:03<01:30, 7.09MB/s]sae_weights.safetensors:   9%|▉         | 64.0M/689M [00:04<00:39, 15.9MB/s]sae_weights.safetensors:  12%|█▏        | 80.0M/689M [00:04<00:24, 24.6MB/s]sae_weights.safetensors:  14%|█▍        | 96.0M/689M [00:04<00:20, 29.3MB/s]sae_weights.safetensors:  15%|█▍        | 100M/689M [00:05<00:19, 29.5MB/s] sae_weights.safetensors:  15%|█▌        | 104M/689M [00:05<00:24, 23.5MB/s]sae_weights.safetensors:  15%|█▌        | 106M/689M [00:05<00:24, 23.5MB/s]sae_weights.safetensors:  16%|█▌        | 109M/689M [00:05<00:24, 23.7MB/s]sae_weights.safetensors:  16%|█▋        | 112M/689M [00:06<00:39, 14.6MB/s]sae_weights.safetensors:  19%|█▊        | 128M/689M [00:06<00:22, 24.5MB/s]sae_weights.safetensors:  21%|██        | 144M/689M [00:06<00:18, 29.3MB/s]sae_weights.safetensors:  22%|██▏       | 149M/689M [00:06<00:17, 31.3MB/s]sae_weights.safetensors:  23%|██▎       | 156M/689M [00:07<00:15, 34.7MB/s]sae_weights.safetensors:  23%|██▎       | 160M/689M [00:07<00:24, 21.8MB/s]sae_weights.safetensors:  26%|██▌       | 176M/689M [00:07<00:17, 29.5MB/s]sae_weights.safetensors:  28%|██▊       | 192M/689M [00:08<00:13, 36.0MB/s]sae_weights.safetensors:  30%|███       | 208M/689M [00:08<00:11, 40.1MB/s]sae_weights.safetensors:  33%|███▎      | 224M/689M [00:08<00:11, 42.0MB/s]sae_weights.safetensors:  35%|███▍      | 240M/689M [00:09<00:10, 42.9MB/s]sae_weights.safetensors:  37%|███▋      | 256M/689M [00:09<00:10, 43.2MB/s]sae_weights.safetensors:  39%|███▉      | 272M/689M [00:09<00:09, 45.2MB/s]sae_weights.safetensors:  42%|████▏     | 288M/689M [00:10<00:09, 43.6MB/s]sae_weights.safetensors:  44%|████▍     | 304M/689M [00:10<00:08, 45.0MB/s]sae_weights.safetensors:  46%|████▋     | 320M/689M [00:11<00:07, 46.7MB/s]sae_weights.safetensors:  49%|████▉     | 336M/689M [00:11<00:07, 45.9MB/s]sae_weights.safetensors:  51%|█████     | 352M/689M [00:12<00:09, 37.4MB/s]sae_weights.safetensors:  53%|█████▎    | 368M/689M [00:12<00:08, 37.9MB/s]sae_weights.safetensors:  56%|█████▌    | 384M/689M [00:12<00:08, 37.9MB/s]sae_weights.safetensors:  58%|█████▊    | 400M/689M [00:13<00:07, 39.3MB/s]sae_weights.safetensors:  60%|██████    | 416M/689M [00:13<00:06, 41.4MB/s]sae_weights.safetensors:  63%|██████▎   | 432M/689M [00:13<00:06, 39.9MB/s]sae_weights.safetensors:  65%|██████▌   | 448M/689M [00:14<00:06, 39.7MB/s]sae_weights.safetensors:  67%|██████▋   | 464M/689M [00:14<00:05, 42.3MB/s]sae_weights.safetensors:  70%|██████▉   | 480M/689M [00:15<00:04, 44.6MB/s]sae_weights.safetensors:  72%|███████▏  | 496M/689M [00:15<00:04, 43.1MB/s]sae_weights.safetensors:  74%|███████▍  | 512M/689M [00:15<00:04, 40.2MB/s]sae_weights.safetensors:  75%|███████▌  | 517M/689M [00:16<00:04, 40.1MB/s]sae_weights.safetensors:  76%|███████▌  | 521M/689M [00:16<00:05, 30.6MB/s]sae_weights.safetensors:  76%|███████▌  | 524M/689M [00:16<00:05, 28.4MB/s]sae_weights.safetensors:  77%|███████▋  | 528M/689M [00:16<00:07, 20.6MB/s]sae_weights.safetensors:  79%|███████▉  | 544M/689M [00:17<00:04, 29.2MB/s]sae_weights.safetensors:  81%|████████  | 560M/689M [00:17<00:03, 33.3MB/s]sae_weights.safetensors:  84%|████████▎ | 576M/689M [00:18<00:03, 34.2MB/s]sae_weights.safetensors:  86%|████████▌ | 592M/689M [00:18<00:02, 38.3MB/s]sae_weights.safetensors:  88%|████████▊ | 608M/689M [00:18<00:01, 41.5MB/s]sae_weights.safetensors:  91%|█████████ | 624M/689M [00:19<00:01, 45.1MB/s]sae_weights.safetensors:  93%|█████████▎| 640M/689M [00:19<00:01, 44.5MB/s]sae_weights.safetensors:  95%|█████████▌| 656M/689M [00:19<00:00, 42.9MB/s]sae_weights.safetensors:  97%|█████████▋| 672M/689M [00:20<00:00, 43.7MB/s]sae_weights.safetensors: 100%|█████████▉| 688M/689M [00:20<00:00, 47.1MB/s]sae_weights.safetensors: 100%|██████████| 689M/689M [00:20<00:00, 33.3MB/s]
Files uploaded successfully.
