{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want:\n",
    "\n",
    "main/control loss for:\n",
    "\n",
    "- GSAE\n",
    "- GSAE finetune\n",
    "- GSAE-phys (sweep L0)\n",
    "- GSAE + SSAE (sweep L0)\n",
    "- clean loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/root/specialised-SAEs\")\n",
    "from datasets import load_dataset\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from sae_lens.jacob.load_sae_from_hf import load_sae_from_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=\"cuda\", dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb49c1424f14c209e17fc2f1beb000e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "expansion=64.safetensors:   0%|          | 0.00/303M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d404272bfd8d47f1ba413e78bac132af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "expansion=64_cfg.json:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "temp_sae/cfg.json temp_sae/sae_weights.safetensors\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gsae_64 = load_sae_from_hf(\"jacobcd52/gpt2-gsae\", \n",
    "                        \"expansion=64.safetensors\", \n",
    "                        \"expansion=64_cfg.json\",\n",
    "                        device=\"cuda\",\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "gsae_16 = load_sae_from_hf(\"jacobcd52/gpt2-gsae\", \n",
    "                        \"expansion=16.safetensors\", \n",
    "                        \"expansion=16_cfg.json\",\n",
    "                        device=\"cuda\",\n",
    "                        dtype=DTYPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owt_tokens has shape torch.Size([44086, 256])\n",
      "total number of tokens: 11 million\n",
      "phys_tokens has shape torch.Size([62879, 256])\n",
      "total number of tokens: 16 million\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get OWT tokens\n",
    "data = load_dataset(\"stas/openwebtext-10k\", split=\"train\")\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=256)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "owt_tokens = tokenized_data[\"tokens\"].cuda()\n",
    "print(\"owt_tokens has shape\", owt_tokens.shape)\n",
    "print(\"total number of tokens:\", int(owt_tokens.numel()//1e6), \"million\")\n",
    "print()\n",
    "# get physics-papers tokens\n",
    "data = load_dataset(\"jacobcd52/physics-papers\", split=\"train[:10%]\")\n",
    "# Define a filter function to remove null entries\n",
    "def remove_null_entries(example):\n",
    "    return all(value is not None and value != '' for value in example.values())\n",
    "# Apply the filter to remove null entries\n",
    "data = data.filter(remove_null_entries)\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=256)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "phys_tokens = tokenized_data[\"tokens\"].cuda()\n",
    "print(\"phys_tokens has shape\", phys_tokens.shape)\n",
    "print(\"total number of tokens:\", int(phys_tokens.numel()//1e6), \"million\")\n",
    "\n",
    "# clean up\n",
    "del tokenized_data, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(\n",
    "        sae_list, \n",
    "        tokens, \n",
    "        num_tokens, \n",
    "        hook_pt = 'blocks.8.hook_resid_pre', \n",
    "        batch_size=16\n",
    "        ):\n",
    "    \n",
    "    # define hook fn to patch in SAE reconstructions, as well as cache the L0\n",
    "    l0_dic = {}\n",
    "    def patch_hook(act, hook):\n",
    "\n",
    "        l0 = 0\n",
    "        out = torch.zeros_like(act)\n",
    "        \n",
    "        for sae in sae_list:\n",
    "            feature_acts = sae.encode_fn(act)\n",
    "            l0 += (feature_acts > 0).to(DTYPE).sum(dim=-1).mean()\n",
    "            out += sae.decode(feature_acts)\n",
    "\n",
    "        l0_dic[0] = l0\n",
    "        return out\n",
    "    \n",
    "    # initialise running variables\n",
    "    total_l0 = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    num_batches = num_tokens // (tokens.shape[1] * batch_size)\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        # get batch\n",
    "        batch = tokens[b*batch_size:(b+1)*batch_size]\n",
    "        total_loss += model.run_with_hooks(\n",
    "            batch,\n",
    "            return_type=\"loss\",\n",
    "            fwd_hooks = [(hook_pt, patch_hook)]\n",
    "        ).item()\n",
    "        total_l0 += l0_dic[0].item()\n",
    "\n",
    "    return total_loss / num_batches, total_l0 / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss(sae_list, tokens, num_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
