{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports & definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jacobcd52/sae_vis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/root/specialised-SAEs/\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sae_lens.sae import SAE\n",
    "from sae_lens.training.training_sae import TrainingSAE\n",
    "import sae_vis\n",
    "from sae_lens.training.activations_store import ActivationsStore\n",
    "from sae_lens.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.sae_training_runner import SAETrainingRunner\n",
    "from sae_lens.jacob.load_sae_from_hf import load_sae_from_hf\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callum imports \n",
    "from IPython import get_ipython # type: ignore\n",
    "ipython = get_ipython(); assert ipython is not None\n",
    "\n",
    "# Standard imports\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import webbrowser\n",
    "import os\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import time\n",
    "\n",
    "# Library imports\n",
    "from sae_vis.utils_fns import get_device\n",
    "from sae_vis.model_fns import AutoEncoder\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "from sae_vis.data_config_classes import SaeVisConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(\n",
    "    activation_store: ActivationsStore,\n",
    "    n_batches_to_sample_from: int = 2**10,\n",
    "    n_prompts_to_select: int = 4096 * 6,\n",
    "    control_mixture: float = 0.5\n",
    "):\n",
    "    all_tokens_list = []\n",
    "\n",
    "    print(\"getting control tokens\")\n",
    "    pbar = tqdm(range(int(control_mixture*n_batches_to_sample_from)))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_control_batch_tokens()\n",
    "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
    "            : batch_tokens.shape[0]\n",
    "        ]\n",
    "        all_tokens_list.append(batch_tokens)\n",
    "\n",
    "    print(\"getting specialised tokens\")\n",
    "    pbar = tqdm(range(int((1-control_mixture)*n_batches_to_sample_from)))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
    "            : batch_tokens.shape[0]\n",
    "        ]\n",
    "        all_tokens_list.append(batch_tokens)\n",
    "\n",
    "    all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "    all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
    "    return all_tokens[:n_prompts_to_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_steps = 10_000 \n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "control_mixture = 0.9\n",
    "lr = 1e-3\n",
    "l1_coefficient = 1\n",
    "expansion_factor = 1\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # JACOB\n",
    "    gsae_repo = \"jacobcd52/gemma2-gsae\",\n",
    "    gsae_filename = \"sae_weights.safetensors\",\n",
    "    gsae_cfg_filename = \"cfg.json\",\n",
    "    is_control_dataset_tokenized=False,\n",
    "    control_mixture=control_mixture,\n",
    "    control_dataset_path=\"Skylion007/openwebtext\" if control_mixture > 0 else None,\n",
    "\n",
    "    dataset_path=\"jacobcd52/physics-papers\",\n",
    "    is_dataset_tokenized=False,\n",
    "\n",
    "    # Data Generating Function (Model + Training Distribution)\n",
    "    architecture=\"gated\",  # we'll use the gated variant.\n",
    "    model_name=\"gemma-2b-it\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.12.hook_resid_pre\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=12,  # Only one layer in the model.\n",
    "    d_in=2048,  # the width of the mlp output.\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=expansion_factor,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=True,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=False,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    # normalize_activations=False, JACOB\n",
    "    # Training Parameters\n",
    "    lr=lr,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=l1_coefficient,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"scratch-ssae-stuff\",\n",
    "    run_name = f\"l1={l1_coefficient}_expansion={expansion_factor}_control_mix={control_mixture}_tokens={batch_size*total_training_steps}_lr={lr}\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=\"cuda\",\n",
    "    seed=42,\n",
    "    n_checkpoints=1,\n",
    "    checkpoint_path=f\"phys_gpt2_ssae_l1_coeff={l1_coefficient}_expansion={expansion_factor}_control_mixture={control_mixture}_tokens={batch_size*total_training_steps}_lr={lr}\",\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "print(\"instantiating ssae\")\n",
    "ssae = SAETrainingRunner(cfg)\n",
    "model = ssae.model\n",
    "activation_store = ssae.activations_store\n",
    "all_tokens_gpt = get_tokens(activation_store, control_mixture=1.0, n_batches_to_sample_from = 2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = load_sae_from_hf(\"jacobcd52/gemma2-ssae-phys\", \n",
    "                       \"l1_coeff=20_tokens=40960000_lr=0.001.safetensors\", \n",
    "                       \"l1_coeff=20_tokens=40960000_lr=0.001_cfg.json\",\n",
    "                       device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "test_feature_idx_gpt = [i for i in range(10)]\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point = sae.cfg.hook_name,\n",
    "    features = test_feature_idx_gpt,\n",
    "    batch_size = 8192//16,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "sae_vis_data_gpt = SaeVisData.create(\n",
    "    encoder = sae,\n",
    "    model = model,\n",
    "    tokens = all_tokens_gpt, # type: ignore\n",
    "    cfg = feature_vis_config_gpt,\n",
    ")\n",
    "\n",
    "filename = \"phys_features_owt.html\"\n",
    "sae_vis_data_gpt.save_feature_centric_vis(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
