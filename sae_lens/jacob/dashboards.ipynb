{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports & definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/jacobcd52/sae_vis.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = 'bfloat16'\n",
    "ctx_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7109411de0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/root/specialised-SAEs/\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sae_lens.sae import SAE\n",
    "from sae_lens.training.training_sae import TrainingSAE\n",
    "import sae_vis\n",
    "from sae_lens.training.activations_store import ActivationsStore\n",
    "from sae_lens.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.sae_training_runner import SAETrainingRunner\n",
    "from sae_lens.jacob.load_sae_from_hf import load_sae_from_hf\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callum imports \n",
    "from IPython import get_ipython # type: ignore\n",
    "ipython = get_ipython(); assert ipython is not None\n",
    "\n",
    "# Standard imports\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import webbrowser\n",
    "import os\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import time\n",
    "\n",
    "# Library imports\n",
    "from sae_vis.utils_fns import get_device\n",
    "from sae_vis.model_fns import AutoEncoder\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "from sae_vis.data_config_classes import SaeVisConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ee1fab82cd4ce8b4dc595db2b40067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained_no_processing(\"gemma-2b-it\", device=\"cuda\", dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owt_tokens has shape torch.Size([20000, 128])\n",
      "total number of tokens: 2 million\n",
      "\n",
      "phys_tokens has shape torch.Size([20000, 128])\n",
      "total number of tokens: 2 million\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get OWT tokens\n",
    "data = load_dataset(\"stas/openwebtext-10k\", split=\"train\")\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=ctx_length)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "owt_tokens = tokenized_data[\"tokens\"][:20_000].cuda()\n",
    "print(\"owt_tokens has shape\", owt_tokens.shape)\n",
    "print(\"total number of tokens:\", int(owt_tokens.numel()//1e6), \"million\")\n",
    "print()\n",
    "\n",
    "# get physics-papers tokens\n",
    "data = load_dataset(\"jacobcd52/physics-papers\", split=\"train[:10%]\")\n",
    "# Define a filter function to remove null entries\n",
    "def remove_null_entries(example):\n",
    "    return all(value is not None and value != '' for value in example.values())\n",
    "# Apply the filter to remove null entries\n",
    "data = data.filter(remove_null_entries)\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=ctx_length)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "phys_tokens = tokenized_data[\"tokens\"][:20_000].cuda()\n",
    "print(\"phys_tokens has shape\", phys_tokens.shape)\n",
    "print(\"total number of tokens:\", int(phys_tokens.numel()//1e6), \"million\")\n",
    "\n",
    "# clean up\n",
    "del tokenized_data, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f2cb479e644dfa9152e213beac6c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)=30_tokens=40960000_lr=0.001.safetensors:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE weights file saved as temp_sae/sae_weights.safetensors\n",
      "Downloading cfg from Hugging Face Hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f560302fd054d6f863377d9be2bf3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)eff=30_tokens=40960000_lr=0.001_cfg.json:   0%|          | 0.00/2.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSAE cfg file saved as temp_sae/cfg.json\n",
      "Loading weights into GSAE from temp_sae/sae_weights.safetensors\n",
      "temp_sae/cfg.json temp_sae/sae_weights.safetensors\n"
     ]
    }
   ],
   "source": [
    "sae = load_sae_from_hf(\"jacobcd52/gemma2-ssae-phys\",\n",
    "                    f\"l1_coeff=30_tokens=40960000_lr=0.001.safetensors\",\n",
    "                    f\"l1_coeff=30_tokens=40960000_lr=0.001_cfg.json\",\n",
    "                    device=\"cuda\",\n",
    "                    dtype=DTYPE)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "38\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# features with freq > 1e-5 on phys data, and freq_phys/freq_owt > 100\n",
    "\n",
    "finetune_phys_ids = [749, 1274, 2346, 2353, 4585, 6447, 8114, 9646, 11407, 11540, 12451, 14503, 14684, 15171, 15246, 15314, 15344, 15536, 16238, 16261, 16545, 16570, 20752, 20916, 22401, 23048, 26239, 29236, 30120, 31045, 31198, 31205, 31530, 31834, 32261]\n",
    "print(len(finetune_phys_ids))\n",
    "\n",
    "gsae_phys_ids = [1274, 1436, 2346, 3212, 4384, 4585, 8114, 10329, 11407, 11540, 12360, 12451, 14503, 14684, 15144, 15246, 15314, 15344, 15536, 16238, 18282, 20752, 21016, 21162, 23048, 23979, 26239, 27357, 27514, 28035, 29218, 29236, 31045, 31198, 31205, 31729, 32084, 32261]\n",
    "print(len(gsae_phys_ids))\n",
    "\n",
    "new_ids = [id for id in finetune_phys_ids[:20] if id not in gsae_phys_ids]\n",
    "print(len(new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93de27db6f843058532788f25d327db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward passes to cache data for vis:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430dba9131be456c9544d691b4687807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting vis data from cached data:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Task                                           </span>┃<span style=\"font-weight: bold\"> Time   </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│ (1) Initialization                             │ 0.01s  │ 0.0%  │\n",
       "│ (2) Forward passes to gather model activations │ 40.23s │ 63.9% │\n",
       "│ (3) Computing feature acts from model acts     │ 7.20s  │ 11.4% │\n",
       "│ (4) Getting data for tables                    │ 0.03s  │ 0.0%  │\n",
       "│ (5) Getting data for histograms                │ 1.27s  │ 2.0%  │\n",
       "│ (6) Getting data for sequences                 │ 14.14s │ 22.4% │\n",
       "│ (7) Getting data for quantiles                 │ 0.12s  │ 0.2%  │\n",
       "└────────────────────────────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTask                                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│ (1) Initialization                             │ 0.01s  │ 0.0%  │\n",
       "│ (2) Forward passes to gather model activations │ 40.23s │ 63.9% │\n",
       "│ (3) Computing feature acts from model acts     │ 7.20s  │ 11.4% │\n",
       "│ (4) Getting data for tables                    │ 0.03s  │ 0.0%  │\n",
       "│ (5) Getting data for histograms                │ 1.27s  │ 2.0%  │\n",
       "│ (6) Getting data for sequences                 │ 14.14s │ 22.4% │\n",
       "│ (7) Getting data for quantiles                 │ 0.12s  │ 0.2%  │\n",
       "└────────────────────────────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223c25dda91240b5aa08a1d81b2e86c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving feature-centric vis:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "feature_vis_config_gpt = SaeVisConfig(\n",
    "    hook_point = sae.cfg.hook_name,\n",
    "    features =  [i for i in range(50)],\n",
    "    batch_size = 4096,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "sae_vis_data_gpt = SaeVisData.create(\n",
    "    encoder = sae,\n",
    "    model = model,\n",
    "    tokens = phys_tokens, # type: ignore\n",
    "    cfg = feature_vis_config_gpt,\n",
    ")\n",
    "\n",
    "filename = \"phys_features.html\"\n",
    "sae_vis_data_gpt.save_feature_centric_vis(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
